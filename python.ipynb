{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First principles of \"doing stuff\" are things like graph and numeric operations, and search and optimizers.\n",
    "\n",
    "So let's… do those.\n",
    "\n",
    "We'll use Python, of course, the slowest gun in the West.    \n",
    "This is in a Jupyter notebook.    \n",
    "It's funny and educational.    \n",
    "Maybe leave.    \n",
    "Maybe read through.    \n",
    "Maybe clone and play with code.    \n",
    "Maybe clone and erase some code and implement for full mastery.    \n",
    "Have fun doing what you want to do.\n",
    "\n",
    "```bash\n",
    "sudo apt install python3 python3-pip\n",
    "pip3 install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "First, the interfaces that we'd like to use, for inspiration.    \n",
    "No need to understand them all completely for now. Understanding goes with implementation, which is below all these.\n",
    "\n",
    "(Cannot run them, only look.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for hyperparameters:\n",
    "\n",
    "```python\n",
    "@state(a=real(0,1), b=one('x', 'y', 'z'), c=one('x', 'y', 'z'))\n",
    "@examples((0.2, 'x'), (0.8, 'z'))\n",
    "def probability_to_char(st, x):\n",
    "    return st.b if x < st.a else st.c\n",
    "\n",
    "print(probability_to_char(0.9)) # 'z'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for a linear decision tree:\n",
    "\n",
    "```python\n",
    "@state(\n",
    "    result = label('num'),\n",
    "    num = one(\n",
    "        0,\n",
    "        1,\n",
    "        compose(lambda x,y: x+y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,y: x-y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,y: x*y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,y: x/y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,a,b,c: b if x<a else c, label('num'), label('num'), label('num'), label('num'), out=label('num')),\n",
    "    )\n",
    ")\n",
    "def hidden_learned_numeric_function(st, x: label('num'), y: label('num')):\n",
    "    return st.result\n",
    "# Can also be written as:\n",
    "# hidden_learned_numeric_function = state( result=… )('result')\n",
    "\n",
    "\n",
    "@examples((1, 10), (2, 15), (3, 16), (4, 5234), (10, 10000))\n",
    "def learned_function(x):\n",
    "    return hidden_learned_numeric_function(x, x*x) + 10\n",
    "\n",
    "print(learned_function(7))\n",
    "\n",
    "state.pprint(state._get_impl(learned_function))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Pattern-matching on an input.\n",
    "import math\n",
    "@state(\n",
    "    result = label('num'),\n",
    "    num = one(\n",
    "        0,\n",
    "        1,\n",
    "        compose(lambda x,y: x+y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,y: x*y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,y: x/y, label('num'), label('num'), out=label('num')),\n",
    "        compose(lambda x,y: math.pow(x,y), label('num'), label('num'), out=label('num')),\n",
    "    )\n",
    ")\n",
    "def hidden_learned_numeric_function2(st, f: one('x', 'y', one.object_id), x: label('num')):\n",
    "    return st.result\n",
    "\n",
    "\n",
    "@examples((1, 2), (2, 4), (3, 8))\n",
    "def learned_function1(x):\n",
    "    return hidden_learned_numeric_function2('x', x)\n",
    "\n",
    "@examples((1, 2), (2, 4), (3, 6))\n",
    "def learned_function2(x):\n",
    "    return hidden_learned_numeric_function2('y', x)\n",
    "\n",
    "@examples((1, 10), (2, 11), (3, 12))\n",
    "def learned_function3(x):\n",
    "    return hidden_learned_numeric_function2(learned_function3, x)\n",
    "\n",
    "print(learned_function1(4), learned_function2(4), learned_function3(4))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persistence:\n",
    "\n",
    "```python\n",
    "@state(\n",
    "    'learned123213',\n",
    "    a = real(0,1)\n",
    ")\n",
    "def met(st):\n",
    "    return st.a\n",
    "for i in range(100):\n",
    "    examples.add(met, out = 0.5 + i/200)\n",
    "\n",
    "state.load('saveToAndLoadFrom.bin', autosave = False)\n",
    "examples.fit(examples.new, examples.timeout(5000))\n",
    "examples.fit(examples.all, examples.timeout(500))\n",
    "state.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State inlining (multiple callsites of the same function in another function get treated as one) (analogous to transfer learning):\n",
    "\n",
    "```python\n",
    "@state(a=one(1,2))\n",
    "@examples(1)\n",
    "def function1(st):\n",
    "    return st.a\n",
    "\n",
    "@state(a=2)\n",
    "@examples(4)\n",
    "def function4(st):\n",
    "    return function1() + st.a\n",
    "\n",
    "print(function1(), function4()) # 1, 4\n",
    "\n",
    "state.pprint(state._get_impl(function1).a) # history(one(1,2), 1)\n",
    "\n",
    "# Accomplished via automatically randomly calling:\n",
    "# state.inline(function4, function1)\n",
    "#   Also pass in inline = True or False or state.apply_copy or max inlining depth (default is 1)\n",
    "#     (or a function that accepts caller and callee, returning one of those four)\n",
    "#     to specify other de/inlining behavior.\n",
    "#   Pass in None instead of function1 to de/inline all called functions' states.\n",
    "#   Pass in None instead of function4 to specify global behavior.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max/min-imization:\n",
    "\n",
    "```python\n",
    "@state(a = real(-1,1), b = real(-1,1), c = real(-1,1))\n",
    "@examples(*( (x*10, float('-inf')) for x in range(-10, 10) ))\n",
    "def minimize_at_points(st, x):\n",
    "    a = st.a * st.a\n",
    "    b = (st.b + 0.1) * (st.b - 0.5)\n",
    "    c = abs(st.c * x)\n",
    "    return a + b + c + x\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([minimize_at_points(x) for x in range(-100, 100)])\n",
    "plt.ylabel('minimize_at_points')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internals: `compose.context`/`.in`/`.out` (used for search) and arbitrary types.\n",
    "\n",
    "```python\n",
    "# There is no one best search method and details,\n",
    "#   so these 'internals' make search simple enough to hopefully be customized easily.\n",
    "with compose.context(num = 1):\n",
    "    with compose.context(num = 2):\n",
    "        with compose.context(num = 3):\n",
    "            print(compose.out(label('num'))) # one(1, 2, 3)\n",
    "\n",
    "with compose.context(1, 3, 5, 7, 9, num = real(0,10)):\n",
    "    x = one(1, 2, label('num'))\n",
    "    print(compose.ins(x)) # one._pattern_match(1, 2, 'num')\n",
    "    print(compose.out(x)) # (1, 2, real(0, 10))\n",
    "    y = compose.type((1, 2, 3), None) # (enum)\n",
    "    print(compose.ins(y)) # (1, 2, 3)\n",
    "    print(compose.out(y)) # None — no further composition needed, usable as-is if found.\n",
    "    z = compose.type(None, lambda x: x if isinstance(x, int) and x <= 5 else None) # (filter)\n",
    "    print(compose.ins(z)) # None\n",
    "    print(compose.out(z)) # (1, 3, 5)\n",
    "    w = compose.type(None, lambda x: x)\n",
    "    print(compose.ins(w)) # None\n",
    "    print(compose.out(w)) # (1, 3, 5, 7, 9, real(0, 10))\n",
    "\n",
    "\n",
    "\n",
    "# Internals: picking from options.\n",
    "import random\n",
    "def random_index(*a):\n",
    "    L = len(a)\n",
    "    return random.int(0, L-1) if L > 0 else None\n",
    "with compose.picker(lambda a: random_index(x for x in a if x>=5)):\n",
    "    with compose.context(1, 5, 10):\n",
    "        top = compose.type(None, lambda x: x)\n",
    "        print(compose.pick(top)) # 5 or 10\n",
    "        print((x for x in compose.picks(top))) # 5,10 or 10,5\n",
    "\n",
    "\n",
    "\n",
    "# Internals: undo-enabled transformations.\n",
    "undo_example_default_a = history(real(0,10), one(1,2,3), 2)\n",
    "undo_example = state(\n",
    "    a = undo_example_default_a\n",
    ")('a')\n",
    "\n",
    "state._set_impl(undo_example, 'a', undo_example_default_a)\n",
    "\n",
    "# The appropriate value will be found much faster than with just a=real(0,10).\n",
    "examples.add(undo_example, out = 3)\n",
    "examples.fit(undo_example, examples.timeout(100))\n",
    "print(undo_example()) # 3\n",
    "# In operations that our library implements, for each type of set,\n",
    "#   we'd like to have set=>subset functions that rely on history to speed up minor changes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search optimization (optimize how fast things are optimized):\n",
    "\n",
    "```python\n",
    "for i in range(10):\n",
    "    start_time = examples.time()\n",
    "    def search_speed(f, got, expected):\n",
    "        return examples._loss(f) * start_time()\n",
    "    with compose.context(metrics = search_speed):\n",
    "        examples.fit(examples.all, examples.timeout(1000))\n",
    "\n",
    "\n",
    "\n",
    "# Memory limiting and optimization.\n",
    "@state(\n",
    "    result = one('x', compose(lambda x: x+1, 'x', 'x'))\n",
    ")\n",
    "def mem_limiting_example(st, x: 'x'):\n",
    "    return st.result\n",
    "state.byte_limit(mem_limiting_example, 100) # Limit the sum of sys.getsizeof()\n",
    "\n",
    "\n",
    "def memory(since = 0):\n",
    "    # Somewhat accurate to kilobytes.\n",
    "    import resource\n",
    "    u = resource.getrusage(resource.RUSAGE_SELF)\n",
    "    mem = u.ru_ixrss + u.ru_idrss + u.ru_isrss\n",
    "    if not mem:\n",
    "        mem = u.ru_maxrss\n",
    "    if sys.platform != 'darwin':\n",
    "        mem = mem * 1024\n",
    "    return mem - since\n",
    "start_memory = memory()\n",
    "with compose.context(metrics = lambda f,g,e: -memory(start_memory)):\n",
    "    examples.fit(examples.all, examples.timeout(5000))\n",
    "\n",
    "# These are areas where it is practically impossible to come up with universally good metrics or optimization way,\n",
    "#   so advanced metric (and search-impl) enumeration and search would be required.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why\n",
    "\n",
    "Ah, the age-old question of \"why does this exist?\".\n",
    "\n",
    "To put it simply, right now we want to make a reliable library for adding structural learning to ML's numerical learning, similar to AutoML frameworks. But our thinking that led to this is broader.\n",
    "\n",
    "Intelligence is beyond static descriptions and beyond static numerics.    \n",
    "Natural language transformer networks, using comments to select which feature is the most appropriate to implement another.    \n",
    "A mental list of tasks that a person does, having spent a lifetime learning when to take on a new task, when to work on the list, when the work is good enough, and when to give up.    \n",
    "Vast groups that co-learned the same meanings and implications of words, and the gradual drift of those meanings and eventually words themselves over time, in groups and individuals alike.    \n",
    "People learning how to adjust the program they wrote in response to errors they see, learning appropriate dynamic contexts of static parameters (if they depend on the phase of the moon, it will be found out), and learning re-usable parts and when to learn them for most effective transfer learning.    \n",
    "Only a fully dynamic thing behaves like that.\n",
    "\n",
    "Here, we hope to try out a new stateful approach to writing software, where only the most important things are formalized, and the rest is learned.\n",
    "\n",
    "We'd like to put lessons of machine learning (mainly \"don't write down one way, write down all ways, and defer choices to the machine\") into a non-numeric form.\n",
    "\n",
    "More, we'd like an arbitrary-program optimization base that can represent and optimize fully-dynamic behavior, then develop it to be more like known intelligence, and ease the transition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carcass\n",
    "\n",
    "Our next step here is to consolidate all those examples into the library's skeleton, which includes full interfaces and comments on how each function is to be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public interface:\n",
    "\n",
    "# state(__name = None, **vars)(func_or_varname)\n",
    "#   load(filename, autosave = True)\n",
    "#   save(filename = last_loaded_filename)\n",
    "#   override(func_id_to_impl) -> context_manager\n",
    "#   pprint(state)\n",
    "#   inline(func = None, inner_func = None, inline = 1)\n",
    "#   byte_limit(func, bytes)\n",
    "#   _get_impl(func, varname = None)\n",
    "#   _set_impl(func, varname, impl)\n",
    "# examples(*args_to_out)(func)\n",
    "#   add(func, *args, out)\n",
    "#   fit(func, stopping_check)\n",
    "#   timeout(ms) -> function finished()->bool\n",
    "#   time() -> function time_since()->ms\n",
    "#   new: list\n",
    "#   all: list\n",
    "#   _loss(func)\n",
    "# compose(func, *arg_sets, out)\n",
    "#   context(*values, **label_set_additions) -> context manager\n",
    "#   ins(object)\n",
    "#   out(object)\n",
    "#   type(enum, filter)\n",
    "#   picker(list_to_index_function) -> context manager\n",
    "#   pick(object)\n",
    "#   picks(object) -> iterator\n",
    "# match(value, branches)\n",
    "#   id\n",
    "# label(name)\n",
    "# history(*past_then_present) datatype\n",
    "# many(*of) datatype\n",
    "# one(*of) datatype\n",
    "# real(min, max) datatype\n",
    "# int(min, max) datatype\n",
    "\n",
    "# Executing a function, with composable arbitrary backprop:\n",
    "#   execute(func, ins = None) -> many(out, exec_state)\n",
    "#   adjust(func, ins, out, dout, exec_state) -> dins\n",
    "\n",
    "# _parse(bytes) -> obj\n",
    "# _serialize(obj) -> bytes\n",
    "\n",
    "import sys # getsizeof\n",
    "import math # isinf\n",
    "import time # clock\n",
    "import random\n",
    "import inspect # getsource\n",
    "import weakref # finalize, WeakValueDictionary\n",
    "from numbers import Number\n",
    "\n",
    "# All datatypes have a uniform repr:\n",
    "#   Struct(head, *data) which inherits from list.\n",
    "_bytes = 0\n",
    "class Struct(list):\n",
    "    def __init__(self, *head_then_args):\n",
    "        global _bytes\n",
    "        super().__init__(head_then_args)\n",
    "        _bytes += sys.getsizeof(self)\n",
    "        # Keep track of byte-precise memory ourselves.\n",
    "    def __del__(self):\n",
    "        global _bytes\n",
    "        _bytes -= sys.getsizeof(self)\n",
    "        # Assuming that structs are immutable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class State:\n",
    "    # Using @staticmethod is too verbose.\n",
    "    # Is there any other way to do non-file-based namespacing in Python?\n",
    "\n",
    "    def __call__(_, __name = None, **kwvars):\n",
    "        \"\"\"Decorator for specifying state state for functions.\n",
    "        A function will have an extra arg in front for getting state; do not store it.\"\"\"\n",
    "        ## is TBD\n",
    "        def decorate(func):\n",
    "            nonlocal __name\n",
    "            if __name is None:\n",
    "                __name = inspect.getsource(func)\n",
    "            ## And set _state_names[__name] to func for save/load.\n",
    "            func.states = {id(func):kwvars}\n",
    "            def replacement(*args, **kwargs):\n",
    "                global _current_func\n",
    "                _current_func = func\n",
    "                with state.override(func.states):\n",
    "                    return func(_current_state_object, *args, **kwargs)\n",
    "            for k,v in vars(func).items():\n",
    "                setattr(replacement, k, v)\n",
    "            return replacement\n",
    "        return decorate\n",
    "    \n",
    "    def load(_, filename, autosave = True):\n",
    "        \"\"\"Loads global state from file.\"\"\"\n",
    "        ## Read file bytes.\n",
    "        ## Turn file bytes into an object graph with _parse(bytes).\n",
    "        ## Set functions' states named in _state_names to what they are in the graph.\n",
    "        pass\n",
    "    \n",
    "    def save(_, filename = None):\n",
    "        \"\"\"Saves global state to file, the last loaded one by default.\"\"\"\n",
    "        ## that = {k:state._get_impl(v) for k,v in _state_names.items()}\n",
    "        ## Get bytes with _serialize(that).\n",
    "        ## Write them.\n",
    "        pass\n",
    "    \n",
    "    def override(_, func_id_to_state):\n",
    "        \"\"\"Returns a context manager that overrides function impls, for inlining.\"\"\"\n",
    "        class StateSetter:\n",
    "            __slots__ = ['fs']\n",
    "            def __init__(self, fs):\n",
    "                self.fs = fs\n",
    "            def __enter__(self):\n",
    "                for func_id, state in self.fs.items():\n",
    "                    _states[func_id] = state\n",
    "            def __exit__(self,x,y,z):\n",
    "                for func_id, state in self.fs.items():\n",
    "                    del _states[func_id]\n",
    "        return StateSetter(func_id_to_state)\n",
    "    \n",
    "    ## Do we need `func` in these three; isn't it always the current func?\n",
    "    def _run_impl(_, func, varname):\n",
    "        \"\"\"Get and execute an impl.\"\"\"\n",
    "        impl = state._get_impl(func, varname)\n",
    "        out, exec_state = execute(impl)\n",
    "        ## And store exec_state in func's current exec_state cell.\n",
    "        return out\n",
    "    \n",
    "    def _get_impl(_, func, varname = None):\n",
    "        \"\"\"Get a function's impl in the current state.\"\"\"\n",
    "        # Lookup in the first override of func in _states.\n",
    "        if id(func) in _states:\n",
    "            state = _states[id(func)]\n",
    "            if varname is None:\n",
    "                return state\n",
    "            elif varname in state:\n",
    "                return state[varname]\n",
    "        return None\n",
    "    \n",
    "    def _set_impl(_, func, varname, impl):\n",
    "        \"\"\"Set a function's impl in the current state.\"\"\"\n",
    "        if id(func) in _states:\n",
    "            state = _states[id(func)]\n",
    "            state[varname] = impl\n",
    "    \n",
    "    def pprint(_, obj):\n",
    "        \"\"\"Pretty-prints an object.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def inline(_, func = None, inner_func = None, inline = 1):\n",
    "        \"\"\"Sets the global state inlining policy.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def byte_limit(_, func, bytes):\n",
    "        \"\"\"Sets the maximum byte count that a function's state can take.\"\"\"\n",
    "        pass\n",
    "\n",
    "state = State()\n",
    "\n",
    "\n",
    "\n",
    "class _CurrentState:\n",
    "    def __getattr__(self, attr):\n",
    "        return state._run_impl(_current_func, attr)\n",
    "\n",
    "_current_state_object = _CurrentState()\n",
    "\n",
    "_states = {}\n",
    "_current_func = None\n",
    "\n",
    "\n",
    "\n",
    "class Examples:\n",
    "    def __call__(self, *args_to_out):\n",
    "        \"\"\"A decorator for associating input-output examples with a function.\"\"\"\n",
    "        def decorate(func):\n",
    "            func.examples = args_to_out\n",
    "            examples.all.append(func)\n",
    "            weakref.finalize(func, examples.all.remove, func)\n",
    "            return func\n",
    "        return decorate\n",
    "    \n",
    "    def _loss(_, func, exs = None):\n",
    "        \"\"\"Computes the loss of a function over all its examples, to be minimized.\"\"\"\n",
    "        if exs is None:\n",
    "            exs = func.examples\n",
    "        dsum = 0\n",
    "        for ex in exs:\n",
    "            # This slice might allocate, meaning that it should be pre-done in `examples`.\n",
    "            # I don't know enough about Python internals.\n",
    "            intended_ins, intended_out = ex[0:-1], ex[-1]\n",
    "            out, exec_state = execute(func, intended_ins)\n",
    "            if not isinstance(intended_out, Number):\n",
    "                dout = 0 if intended_out == out else 1\n",
    "            elif not math.isinf(intended_out):\n",
    "                dout = abs(out - intended_out)\n",
    "            elif intended_out > 0: # +∞\n",
    "                dout = -out\n",
    "            else: # -∞\n",
    "                dout = out\n",
    "            dsum += dout\n",
    "            ## We have exec_state here,\n",
    "            ##   we could use it by passing it to `adjust`,\n",
    "            ##   or by returning a random one.\n",
    "            ## But \"when\" is unclear.\n",
    "            ##   We'd like to optimize that automatically, later.\n",
    "        return dsum\n",
    "    \n",
    "    def add(_, func, *args, out):\n",
    "        \"\"\"Adds an example to a function's example list.\"\"\"\n",
    "        func.examples.append((*args, out))\n",
    "    \n",
    "    def fit(_, func = None, stopping_check = None):\n",
    "        \"\"\"Executes and adjusts a function on any of its examples.\n",
    "        Returns when stopping_check returns True.\"\"\"\n",
    "        if stopping_check is None:\n",
    "            stopping_check = examples.timeout(500)\n",
    "        ## while not stopping_check():\n",
    "        ##   pick random example\n",
    "        ##   execute\n",
    "        ##   adjust\n",
    "        # (Or add up loss and sample state of several examples and adjust.)\n",
    "        pass\n",
    "    \n",
    "    def timeout(ms):\n",
    "        \"\"\"Returns a function that returns True when the given milliseconds have passed.\"\"\"\n",
    "        end_s = time.clock() + ms/1000\n",
    "        def finished():\n",
    "            return time.clock() <= end_s \n",
    "        return finished\n",
    "    \n",
    "    def time():\n",
    "        \"\"\"Returns a function that returns milliseconds passed since its creation.\"\"\"\n",
    "        start = time.clock()\n",
    "        def time_since():\n",
    "            return (time.clock() - start)*1000\n",
    "        return time_since\n",
    "    \n",
    "    new = []\n",
    "    all = []\n",
    "\n",
    "examples = Examples()\n",
    "\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __call__(_, *arg_sets, out):\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def context(_, *values, **label_set_additions): # -> context manager\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def ins(_, obj):\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def out(_, obj):\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def type(_, enum, filter):\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def picker(_, list_to_index_function): # -> context manager\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def pick(_, obj):\n",
    "        \"\"\"\"\"\"\n",
    "    \n",
    "    def picks(_, obj): # -> iterator\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "compose = Compose()\n",
    "\n",
    "\n",
    "\n",
    "class Label:\n",
    "    __slots__ = ('name', '__weakref__')\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Label):\n",
    "            return self.name == other.name\n",
    "        return False\n",
    "    # Python 3 needs no __ne__\n",
    "\n",
    "_label_cache = weakref.WeakValueDictionary({})\n",
    "\n",
    "def label(name):\n",
    "    \"\"\"Returns an object that is guaranteed to be the same for equal values of `name`.\"\"\"\n",
    "    if name not in _label_cache:\n",
    "        L = Label(name) # Why is putting it on the same line make it call the getter?\n",
    "        _label_cache[name] = L\n",
    "    return _label_cache[name]\n",
    "\n",
    "\n",
    "\n",
    "class Match:\n",
    "    def __call__(self, value, branches):\n",
    "        \"\"\"\"\"\"\n",
    "        pass\n",
    "    id = \"\"\"Pattern-matches on id(object).\"\"\"\n",
    "\n",
    "match = Match()\n",
    "\n",
    "\n",
    "\n",
    "class History:\n",
    "    \"\"\"A transformed value, able to be returned to its past state.\"\"\"\n",
    "    def __call__(self, *past_then_present):\n",
    "        return Struct(History, *past_then_present)\n",
    "\n",
    "history = History()\n",
    "\n",
    "\n",
    "\n",
    "class Many:\n",
    "    \"\"\"Basically an array.\n",
    "    Multiple values at once, able to be decomposed into each with `access_many`.\n",
    "    When a value of a `many(…)` set is an input, becomes decomposed into each part.\n",
    "    When an output, generates each branch, then puts results into an array.\"\"\"\n",
    "    def __call__(self, *of):\n",
    "        return Struct(Many, *of)\n",
    "\n",
    "many = Many()\n",
    "\n",
    "def access_many(m, index):\n",
    "    return m[index]\n",
    "\n",
    "\n",
    "\n",
    "class One:\n",
    "    \"\"\"Basically a choice.\n",
    "    Any value from ones listed, able to be recognized with `match`.\n",
    "    When a value of a `one(…)` set is an input, becomes pattern-matched.\n",
    "    When an output, selects a random branch to go to (with a pattern-match).\"\"\"\n",
    "    def __call__(self, *of):\n",
    "        return Struct(One, *of)\n",
    "\n",
    "one = One()\n",
    "\n",
    "\n",
    "\n",
    "class Real:\n",
    "    \"\"\"Any scalar number from min to max.\"\"\"\n",
    "    def __call__(self, min, max):\n",
    "        return Struct(Real, min, max)\n",
    "\n",
    "real = Real()\n",
    "\n",
    "\n",
    "\n",
    "class Int:\n",
    "    \"\"\"Any integer from min to max.\"\"\"\n",
    "    def __call__(self, min, max):\n",
    "        return Struct(Int, min, max)\n",
    "\n",
    "int = Int()\n",
    "\n",
    "\n",
    "\n",
    "def execute(func, ins = None): # -> many(out, exec_state)\n",
    "    while True:\n",
    "        if isinstance(func, Struct):\n",
    "            if func[0] is Real:\n",
    "                func = random.uniform(func[1], func[2])\n",
    "            elif func[0] is Int:\n",
    "                func = random.randint(func[1], func[2])\n",
    "            ## Also handle Many via actual recursion.\n",
    "            elif func[0] is One:\n",
    "                i = random.randint(1, len(func)-1)\n",
    "                func = func[i]\n",
    "            elif func[0] is History:\n",
    "                func = func[-1]\n",
    "        ## Also execute if an SSA.\n",
    "        elif isinstance(func, Label):\n",
    "            func = state._get_impl(_current_func, func.name)\n",
    "        elif callable(func) and ins is not None:\n",
    "            return func(*ins), None\n",
    "        else:\n",
    "            return func, None\n",
    "def adjust(func, ins, out, dout, exec_state): # -> dins\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def _parse(b):\n",
    "    pass\n",
    "def _serialize(obj):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midway through, I turned my brain off and went coding and learning Python along the way, so this carcass crawls with maggots: setting and getting static state works, setting examples works (but not fitting to them), flyweight labels work. Did not touch composition nor parsing+serialization, nor specialization nor execution.\n",
    "\n",
    "I have struggled with the Python language in a few places.    \n",
    "Following a reference to its definition is burdensome enough that I need to try and mentally track as much scope as I can.    \n",
    "I can't be completely sure that other code won't read the properties I'm defining.    \n",
    "I'm not sure about performance of particular things.    \n",
    "Namespacing is weird and causes semantic noise.    \n",
    "But that doesn't mean that some super language should be made that will have no mistakes in its design, even if that possibility seems closer every year.    \n",
    "Certainly, efforts toward that can be made, and each will improve the situation. That's the danger of static-goal universal optimizers: optimizers that outperform them probably exist.    \n",
    "Planning is everything and plans are nothing, a world model beats expert knowledge, a language is irrelevant next to the ability to make one, and dynamic is always better than static.    \n",
    "That's why I'm exploring this library of dynamic generation.\n",
    "\n",
    "Let's excise bugs by looking at how the implemented functionality behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x y\n",
      "z x x\n",
      "2\n",
      "x x\n",
      "y y y\n",
      "2\n",
      "y x\n",
      "x x y\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "@state(a=real(0,1), b=one('x', 'y', 'z'), c=one('x', 'y', 'z'))\n",
    "@examples((0.2, 'x'), (0.8, 'z'))\n",
    "def probability_to_char(st, x):\n",
    "    return st.b if x < st.a else st.c\n",
    "\n",
    "for _ in range(3):\n",
    "    print(probability_to_char(0.2), probability_to_char(0.8))\n",
    "    print(probability_to_char(0.2), probability_to_char(0.2), probability_to_char(0.2))\n",
    "    print(examples._loss(probability_to_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss should be `0`/`1`/`2` (count of failed examples), and everything should vary constantly, because we don't sometimes rewrite state by specializing, and pick everything dynamically.\n",
    "\n",
    "Rewriting rules and specializing with history (and `examples.fit`) should be next, to make the first example actually work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History\n",
    "\n",
    "I've been thinking about program search and realized something.\n",
    "\n",
    "Random search or evolution are: pick a random part to put into result, or pick a random part to alter/crossover randomly.\n",
    "\n",
    "(Neural networks could be used to estimate/learn how good a choice and a resulting graph are [[Y]](https://arxiv.org/pdf/1910.11858), but structures of search and NNs are still static, and NNs' messy vocabulary makes \"learning\" mean only its particular kind of change. I want another change, the real search of structure.)\n",
    "\n",
    "But that arbitrary choice can be much more than picking a random number each time and being satisfied.\n",
    "\n",
    "We can remember the choice and maybe change it later, or replace it with a choice from a subset, or decide what to do with an arbitrary computation, generated with all this too; then maybe remember our work somewhere, decide when to forget.\n",
    "\n",
    "This needs state, but if we have state, we can learn it.\n",
    "\n",
    "And so, to try to reach and push the state-of-the-art on search, the idea of this library was born.\n",
    "\n",
    "---\n",
    "\n",
    "Previously, I spent half a year making a programming language that is perfect, has many powerful features, and is so uniform it can be written automatically.\n",
    "\n",
    "But I realized: every new feature is another feature away from what allows intelligent behavior.\n",
    "\n",
    "For that, a primitive SSA is better than very convenient semantics, and a library serves better than a full language.\n",
    "\n",
    "A mind is not given to you, and must be learned from the start: 'nothing' is indistinguishable from 'everything', but 'something' is neither.\n",
    "\n",
    "I know a lot of people blame how primitive code entry tools are, but from what I've seen, the only and real problem is the lack of intelligence in machines: 50% more thoughts captured will never equal a mind. Just fools blame tools.\n",
    "\n",
    "To help that, we must learn to change without fear.    \n",
    "Find the everythings that can give rise to all the somethings, implement them, and make a system to learn something simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specializing with history\n",
    "\n",
    "For real this time.\n",
    "\n",
    "We want to be able to specify a function, that will turn an executable value in a state (`impl`) into its special case; we'd then put `history(Old, New)` back.\n",
    "\n",
    "We can't just say \"hey, user, just write whatever you want in this spot\", we have to handle all cases that we've made and connections between them.    \n",
    "In other words, we need to explicitly do a DAG rewrite (directed acyclic graph — basically, where objects are created one-by-one, with immutable-at-creation-time connections).    \n",
    "Say, `rewritten(impl, func)` is the graph rewrite.\n",
    "\n",
    "What does rewriting a thing with connections mean?    \n",
    "Node type (whether it's a `One` or `Real` or others) is important.    \n",
    "Rewrite connections (without repeating work), then rewrite the thing. There might not be connections, which we'll have to check for.    \n",
    "Maybe we don't rewrite a particular node, but still want to build up some estimate for decision-making, so we need an input and an output for that.    \n",
    "Which means that inputs of a rewriting function are (informally) `(estimate | None, node)`, where it's a good idea to match the first item in `node` by object id; and outputs are `many(estimate, node_becomes | None)`.    \n",
    "`node_becomes` here is made by decomposing `node`, and later we'll have to specify a complete basic set of rewrites. That decomposition won't have access to new nodes, so we'll have to update `node_becomes` manually in `rewritten`.\n",
    "\n",
    "Where would we use this function? We could try doing it with a 10% chance in `execute`, or make `adjust` walk the DAG and rewrite an impl with a 1% chance.    \n",
    "Inability to find a good place for structural change may be discouraging, but that's what \"we'll come back to dynamically optimize the search itself later\" is for.\n",
    "\n",
    "Enough talk, let's program it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewritten(impl, func):\n",
    "    # Walk the graph, apply `func(recursive_estimate, *node)` to each node.\n",
    "    def walk(node, func, env):\n",
    "        \"\"\"Fills a dictionary with graph nodes' rewriting results and recursive estimates.\n",
    "        `node` is a list with the node type being the first item and graph edges following, or anything else.\n",
    "        `func` is like `compose('estimate', node, out=many('estimate', 'node_becomes'))`, decomposing nodes up to depth of 1.\n",
    "        `env` is a dict from id(node) to the node's recursive estimate and node_becomes.\"\"\"\n",
    "\n",
    "        # The graph-walk header:\n",
    "        if id(node) in env:\n",
    "            return env[id(node)][0]\n",
    "        env[id(node)] = None # Unneeded if there are no cycles, but good to remember.\n",
    "\n",
    "        # Get and sum estimates of children, then pass that to `estimate`.\n",
    "        ## (Any other order-independent number op can be used: mult, mean, min/max.)\n",
    "        # Every one of our datatypes is a Struct, so getting connections is very simple.\n",
    "        s = None\n",
    "        is_struct = isinstance(node, Struct) and len(node) >= 1\n",
    "        post = Struct(*node) if is_struct else node\n",
    "        any_change = False\n",
    "        if is_struct:\n",
    "            for i in range(1, len(node)):\n",
    "                child_est = walk(node[i], func, env)\n",
    "                post[i] = env[id(node[i])][1]\n",
    "                if post[i] is not node[i]: any_change = True\n",
    "                if child_est is not None:\n",
    "                    s = child_est if s is None else s + child_est\n",
    "\n",
    "        # Collect post-rewrite dependencies in `post`.\n",
    "        s, becomes = func(s, post)\n",
    "\n",
    "        # Remember the rewrite.\n",
    "        if becomes is None:\n",
    "            becomes = post if any_change else node\n",
    "        env[id(node)] = (s, becomes)\n",
    "        return s\n",
    "    env = {}\n",
    "    walk(impl, func, env)\n",
    "    return env[id(impl)][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a complete implementation of rewriting, there should also be its adjusting part to balance out the execution part we've just made: remember `env`, then post-order traversal of execution becomes pre-order traversal of adjustment.\n",
    "\n",
    "With this, what `adjust` should be and do becomes more clear: the `@attr(adjust = adjust_override)` decorator for easily specifying its overrides, and `adjust` itself should propagate in a breadth-first manner, and handle visiting-same-node-many-times (where adjustments should be summed).\n",
    "\n",
    "We won't do that for now, because we have a bigger problem: lacking a representation for computations. This problem may or may not make us rewrite rewriting.\n",
    "\n",
    "Example usage of `rewritten`, to excise bugs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[__main__.One,\n",
       "  [__main__.Real, 1, 3],\n",
       "  [__main__.Real, 1, 3],\n",
       "  [__main__.Real, 2, 4],\n",
       "  [__main__.Real, 1, 6],\n",
       "  15],\n",
       " [__main__.One,\n",
       "  [__main__.Real, 1, 3],\n",
       "  4,\n",
       "  [__main__.Real, 1, 5],\n",
       "  [__main__.Real, 1, 6],\n",
       "  15],\n",
       " [__main__.One,\n",
       "  3,\n",
       "  [__main__.Real, [__main__.Real, 0, 1], 4],\n",
       "  [__main__.Real, 1, 5],\n",
       "  [__main__.Real, 3, 4],\n",
       "  15],\n",
       " [__main__.One, 1, 4, [__main__.Real, 2, 4], [__main__.Real, 1, 6], 15],\n",
       " [__main__.One,\n",
       "  3,\n",
       "  [__main__.Real, [__main__.Real, 0, 1], 4],\n",
       "  [__main__.Real, 1, 5],\n",
       "  [__main__.Real, 3, 4],\n",
       "  15]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def real_rewrites(_, a, b):\n",
    "    from numbers import Number\n",
    "    if isinstance(a, Number) and isinstance(b, Number):\n",
    "        if a + 4 < b:\n",
    "            return real(a+2, b-2)\n",
    "        if a + 2 < b:\n",
    "            return real(a+1, b-1)\n",
    "    return a if random.randint(0,1) == 0 else b\n",
    "\n",
    "def r(_, node):\n",
    "    if isinstance(node, Struct) and node[0] is Real:\n",
    "        if random.randint(0,1) == 0: # 50%\n",
    "            return 0, real_rewrites(*node)\n",
    "    return 0, None\n",
    "\n",
    "[rewritten(one(real(1,3), real(real(0,1),4), real(1,5), real(1,6), 15), r) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, for *real* real this time, specialization with history, also known as fearless rewriting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:',\n",
       " [__main__.One,\n",
       "  [__main__.History, [__main__.Real, 1, 3], 2.978538883228528],\n",
       "  [__main__.Real, [__main__.Real, 0, 1], 4],\n",
       "  [__main__.Real, 1, 5],\n",
       "  [__main__.History, [__main__.Real, 1, 6], 1.264943777428634],\n",
       "  15],\n",
       " '2:',\n",
       " [__main__.One,\n",
       "  [__main__.History,\n",
       "   [__main__.History,\n",
       "    [__main__.History, [__main__.Real, 1, 3], 1.5327327188609798],\n",
       "    2.978538883228528],\n",
       "   [__main__.History, [__main__.Real, 1, 3], 1.5327327188609798]],\n",
       "  [__main__.Real, [__main__.Real, 0, 1], 4],\n",
       "  [__main__.History, [__main__.Real, 1, 5], 1.104872527107211],\n",
       "  [__main__.History,\n",
       "   [__main__.History, [__main__.Real, 1, 6], 1.264943777428634],\n",
       "   [__main__.Real, 1, 6]],\n",
       "  15],\n",
       " 'back:',\n",
       " [__main__.One,\n",
       "  [__main__.Real, 1, 3],\n",
       "  [__main__.Real, [__main__.Real, 0, 1], 4],\n",
       "  [__main__.Real, 1, 5],\n",
       "  [__main__.Real, 1, 6],\n",
       "  15]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numbers import Number\n",
    "\n",
    "def real_specialize(_, a, b):\n",
    "    if isinstance(a, Number) and isinstance(b, Number):\n",
    "        return random.uniform(a, b)\n",
    "\n",
    "def one_specialize(_, *opt):\n",
    "    return random.choice(opt)\n",
    "\n",
    "def history_generalize(_, past, present):\n",
    "    return past\n",
    "\n",
    "def specialize_y(_, node):\n",
    "    becomes = None\n",
    "    if isinstance(node, Struct) and random.randint(0,1) == 0: # 50%\n",
    "        if node[0] is Real:\n",
    "            becomes = real_specialize(*node)\n",
    "        if node[0] is One:\n",
    "            becomes = one_specialize(*node)\n",
    "        if node[0] is History and len(node) == 3:\n",
    "            becomes = history_generalize(*node)\n",
    "    if becomes is not None:\n",
    "        becomes = history(node, becomes)\n",
    "    return 0, becomes\n",
    "\n",
    "def to_initial(_, node):\n",
    "    if isinstance(node, Struct) and node[0] is History:\n",
    "        # Gotta get back, back to the past\n",
    "        return 0, history_generalize(*node)\n",
    "    return 0, None\n",
    "\n",
    "def test():\n",
    "    initial = one(real(1,3), real(real(0,1),4), real(1,5), real(1,6), 15)\n",
    "    post1 = rewritten(initial, specialize_y)\n",
    "    post2 = rewritten(post1, specialize_y)\n",
    "    # The specialize-y function can be chained infinitely,\n",
    "    #   and won't get stuck due to not perfectly-cyclic rewriting rules.\n",
    "    back = rewritten(post2, to_initial)\n",
    "    return ['1:', post1, '2:', post2, 'back:', back]\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In a real implementation, this should be done at execution or adjustment.)\n",
    "\n",
    "I know what you're thinking.\n",
    "\n",
    "\"Why not just execute the whole impl, and add that with history? Could have been done in 1 line.\"\n",
    "\n",
    "The answer is, because this approach won't teach anything.\n",
    "\n",
    "We're exploring without a crystal-clear idea of what we want, so we need to make damn sure that we're teaching ourselves something that may be useful. This will pay dividends in the sequel.    \n",
    "We wanted to handle structure properly, and structure *is* generally a graph, so we made (most of) a graph rewriting routine, so general that it can be used for a graph neural network or any search through quantized rewrites.    \n",
    "We found and made use of some principles: \"always make space for a same-type input+output pair, for customizability/learnability by users\", and \"randomly apply any of these rules\".    \n",
    "And we simplified rewriting until it couldn't be simplified.\n",
    "\n",
    "Maybe this code will be superseded, but its spirit will live on in other code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition\n",
    "\n",
    "Before we can do anything at all interesting, we must be able to handle `compose`d computations properly.\n",
    "\n",
    "There are two parts to that: execution and generation.\n",
    "\n",
    "For generation, we'll need every way that output can possibly be computed from inputs.    \n",
    "Pattern-matching on an arbitrary index to select the branch for the output.   \n",
    "Pattern-matching on inputs.    \n",
    "Decomposing inputs.    \n",
    "Composing output.    \n",
    "Looking at past values.    \n",
    "Looking at future values, and adjusting once available.    \n",
    "Matching input types to output types to compose functions.     \n",
    "Creating many outputs, and predicting how well each of them will do.    \n",
    "Numeric representations, and mixing every input into every output (neural nets).    \n",
    "And don't forget about dynamic partial re-generation in rewriting.    \n",
    "And don't forget loops and/or recursion.\n",
    "\n",
    "but **other**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "It may come as a surprise to some, but function calls compose via inputs. It's true.\n",
    "\n",
    "Which means that a function call should be represented with some object that stores the function to call and its inputs, which could be other such objects.    \n",
    "We need some sort of graph structure.    \n",
    "Like `Struct`.    \n",
    "Yeah, that covers it entirely.    \n",
    "In `execute`, if the `Struct` is a function, compute its inputs then call it.    \n",
    "That big `if` nest can be replaced with one branch-to-data thing. (In fact, it had a big mistake: not recursing on inputs.)\n",
    "\n",
    "If you're used to programming in programming languages, you're probably confused.    \n",
    "Where are variable bindings?    \n",
    "Where are instruction sequences?\n",
    "\n",
    "Unneeded.\n",
    "\n",
    "It's inconvenient to explicitly generate those, and rewriting becomes either really tricky or near-useless.    \n",
    "\n",
    "But they do need some handling.\n",
    "\n",
    "For variable analogues, we won't recompute nodes we've already computed in the current Python function call.    \n",
    "We'll do this with a dict cache.    \n",
    "(Note that if we had all nodes in a linear array, our internal representation would have been called SSA form — static single assignment: assigning each computed value to one variable. This would have replaced dict accesses with much more efficient list accesses. The best option, as always, is both: a DAG for rewriting, and its updated SSA form for execution. But it's complex, so we won't do that here.)    \n",
    "Keeping all intermediate values does not reuse the CPU caches and so is inefficient, but we'll want to have `adjust` which will need all the values.\n",
    "\n",
    "For sequence analogues, we'll need to ensure the lack of cycles, to know what is computed before what.    \n",
    "I mean, what is a cycle in computation?    \n",
    "A link to the past, to represent state? But which past, one execution ago or the execution where the phase of the moon was a werewolf?    \n",
    "Or to the future, predicting a value that's not yet available? But predicting in what manner, and how is its accuracy ensured?    \n",
    "No, a cycle is an error.    \n",
    "And while making each constructed node immutable is enough to abolish cycles, rewriting can generally create them, so we'll need to remember that in generation of rewrites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cache = None # dict from id(node) to result of execute_node\n",
    "_sub = None # dict from id(node) to None or [id(execute_func), _cache, _sub]\n",
    "\n",
    "_outer_node = None # If _cache is set, this must be set too before calling a wrapped func.\n",
    "def _get_outer_node(): return _outer_node\n",
    "def _set_outer_node(to):\n",
    "    global _outer_node\n",
    "    _outer_node = to\n",
    "\n",
    "def _fallthrough(x):\n",
    "    if isinstance(x, Struct) and x[0] is History: x = x[-1]\n",
    "    return x\n",
    "\n",
    "def execute_node(x):\n",
    "    \"\"\"Execute a node inside a wrapped function.\"\"\"\n",
    "    if isinstance(x, Label):\n",
    "        x = state._get_impl(_current_func, x.name)\n",
    "    if isinstance(x, Struct):\n",
    "        # See if in cache:\n",
    "        if id(x) in _cache:\n",
    "            return _cache[id(x)]\n",
    "        _cache[id(x)] = None\n",
    "        if _fallthrough(x) is x:\n",
    "            # Compute args:\n",
    "            args = [execute_node(x[i]) for i in range(1, len(x))]\n",
    "            # Call the function, and cache and return the result:\n",
    "            prev_outer_node = _get_outer_node()\n",
    "            _set_outer_node(x)\n",
    "            try:\n",
    "                result = x[0].call(*args) if hasattr(x[0], 'call') else x[0](*args)\n",
    "            finally:\n",
    "                _set_outer_node(prev_outer_node)\n",
    "        else:\n",
    "            result = execute_node(_fallthrough(x))\n",
    "        _cache[id(x)] = result\n",
    "        return result\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def wrap_function(f, initial_state):\n",
    "    \"\"\"Wrap a function with intro/outro that set up state and cache properly.\"\"\"\n",
    "    def execute_func(*args):\n",
    "        \"\"\"Change some stuff, execute the wrapped function, then restore that stuff.\"\"\"\n",
    "        global _cache, _current_func\n",
    "        prev_current_func, _current_func = _current_func, execute_func\n",
    "        prev_cache, _cache = _cache, {}\n",
    "        with SetExecState(execute_func, _cache):\n",
    "            try: # Call f:\n",
    "                with state.override(execute_func.states):\n",
    "                    return f(_current_state_object, *args)\n",
    "            finally:\n",
    "                # Restore:\n",
    "                _current_func = prev_current_func\n",
    "                _cache = prev_cache\n",
    "\n",
    "    f.states = {id(execute_func):initial_state}\n",
    "    for k,v in vars(f).items():\n",
    "        setattr(execute_func, k, v)\n",
    "    return execute_func\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SetExecState:\n",
    "    \"\"\"A context manager for remembering execution state that needs to be passed to the adjuster.\n",
    "    If this is used, then GetExecState must also be used in the adjuster.\n",
    "    See ExecState.\"\"\"\n",
    "    __slots__ = 'func', 'state', 'outer_sub', 'i'\n",
    "    def __init__(self, func, state):\n",
    "        self.func = func\n",
    "        self.state = state\n",
    "    def __enter__(self):\n",
    "        global _sub\n",
    "        self.outer_sub, _sub = _sub, {}\n",
    "        self.i = id(_outer_node)\n",
    "    def __exit__(self,x,y,z):\n",
    "        global _sub\n",
    "        os, i = self.outer_sub, self.i\n",
    "        if os is None: return\n",
    "        if i not in os:\n",
    "            os[i] = []\n",
    "        os[i].append(id(self.func))\n",
    "        os[i].append(_sub)\n",
    "        os[i].append(self.state)\n",
    "        _sub = os\n",
    "\n",
    "class GetExecState:\n",
    "    \"\"\"A context manager for remembering execution state in the adjuster after SetExecState.\n",
    "    \n",
    "    See ExecState.\"\"\"\n",
    "    __slots__ = 'func', 'outer_sub'\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __enter__(self):\n",
    "        global _sub\n",
    "        i, os = id(_outer_node), _sub\n",
    "        self.outer_sub = os\n",
    "        if i in os:\n",
    "            for j in range(len(os[i]), 0, -3): # Stack.\n",
    "                if os[i][j-3] == id(self.func):\n",
    "                    # Hoping that subfunctions are unique is the best we can hope for\n",
    "                    #   without analyzing Python's internal representation of functions.\n",
    "                    _sub = os[i][j-2]\n",
    "                    state = os[i][j-1]\n",
    "                    del os[i][j-3:j]\n",
    "                    # By removing, we can predict gradients to save memory\n",
    "                    #   (leave the grad prediction there, use up the grad in adjusting, then adjust prediction).\n",
    "                    return state\n",
    "        raise AssertionError('GetExecState that did not have SetExecState')\n",
    "    def __exit__(self,x,y,z):\n",
    "        global _sub\n",
    "        _sub = self.outer_sub\n",
    "        \n",
    "class ExecState:\n",
    "    \"\"\"A context manager that allows connecting execution and adjustment.\n",
    "\n",
    "        with ExecState():\n",
    "            with SetExecState(x, {}):\n",
    "                # execute x\n",
    "            with GetExecState(x) as state:\n",
    "                # adjust x\n",
    "    \"\"\"\n",
    "    __slots__ = 's', 'n'\n",
    "    def __enter__(self):\n",
    "        global _sub, _outer_node\n",
    "        self.s, _sub = _sub, {}\n",
    "        self.n, _outer_node = _outer_node, None\n",
    "    def __exit__(self,x,y,z):\n",
    "        global _sub, _outer_node\n",
    "        _sub = self.s\n",
    "        _outer_node = self.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This execution layer, like in programming languages… It brings me back.    \n",
    "I remembered my childhood. My pet rat was beautiful, until old age killed her in my hands. No pets since.\n",
    "\n",
    "We also need to specify those `call` attributes, and plug `wrap_function` into `state`. Mostly copying and pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Many:\n",
    "    \"\"\"Basically an array.\n",
    "    Multiple values at once, able to be decomposed into each with `access_many`.\n",
    "    When a value of a `many(…)` set is an input, becomes decomposed into each part.\n",
    "    When an output, generates each branch, then puts results into an array.\"\"\"\n",
    "    def __call__(self, *of):\n",
    "        return Struct(Many, *of)\n",
    "    def call(*of):\n",
    "        return list(of)\n",
    "many = Many()\n",
    "def access_many(m, index):\n",
    "    return m[index]\n",
    "\n",
    "\n",
    "\n",
    "class One:\n",
    "    \"\"\"Basically a choice.\n",
    "    Any value from ones listed, able to be recognized with `match`.\n",
    "    When a value of a `one(…)` set is an input, becomes pattern-matched.\n",
    "    When an output, selects a random branch to go to (with a pattern-match).\"\"\"\n",
    "    def __call__(self, *of):\n",
    "        return Struct(One, *of)\n",
    "    def call(*of):\n",
    "        return random.choice(of)\n",
    "one = One()\n",
    "\n",
    "\n",
    "\n",
    "class Real:\n",
    "    \"\"\"Any scalar number from min to max.\"\"\"\n",
    "    def __call__(self, min, max):\n",
    "        return Struct(Real, min, max)\n",
    "    def call(min, max):\n",
    "        return random.uniform(min, max)\n",
    "real = Real()\n",
    "\n",
    "\n",
    "\n",
    "class Int:\n",
    "    \"\"\"Any integer from min to max.\"\"\"\n",
    "    def __call__(self, min, max):\n",
    "        return Struct(Int, min, max)\n",
    "    def call(min, max):\n",
    "        return random.randint(min, max)\n",
    "int = Int()\n",
    "\n",
    "\n",
    "\n",
    "class Bool:\n",
    "    \"\"\"Either False or True.\"\"\"\n",
    "    def __call__(self):\n",
    "        return Struct(Bool)\n",
    "    def call():\n",
    "        return random.randint(0,1) == 0\n",
    "bool = Bool()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class State:\n",
    "    def __call__(_, __name = None, **kwvars):\n",
    "        \"\"\"Decorator for specifying state state for functions.\n",
    "        A function will have an extra arg in front for getting state; do not store it.\"\"\"\n",
    "        ## is TBD\n",
    "        def decorate(func):\n",
    "            nonlocal __name\n",
    "            if __name is None:\n",
    "                __name = inspect.getsource(func)\n",
    "            ## And set _state_names[__name] to func for save/load.\n",
    "            return wrap_function(func, kwvars)\n",
    "        return decorate\n",
    "    \n",
    "    def override(_, func_id_to_state):\n",
    "        \"\"\"Returns a context manager that overrides function impls, for inlining.\"\"\"\n",
    "        class StateSetter:\n",
    "            __slots__ = ['fs']\n",
    "            def __init__(self, fs):\n",
    "                self.fs = fs\n",
    "            def __enter__(self):\n",
    "                for func_id, state in self.fs.items():\n",
    "                    _states[func_id] = state\n",
    "            def __exit__(self,x,y,z):\n",
    "                for func_id, state in self.fs.items():\n",
    "                    if _states[func_id] is state:\n",
    "                        del _states[func_id]\n",
    "        return StateSetter(func_id_to_state)\n",
    "    \n",
    "    def _get_impl(_, func, varname = None):\n",
    "        \"\"\"Get a function's impl in its state.\"\"\"\n",
    "        # Lookup in the first override of func in _states.\n",
    "        if id(func) in _states:\n",
    "            state = _states[id(func)]\n",
    "            if varname is None:\n",
    "                return state\n",
    "            elif varname in state:\n",
    "                return state[varname]\n",
    "        return None\n",
    "    \n",
    "    def _set_impl(_, func, varname, impl):\n",
    "        \"\"\"Set a function's impl in its state.\"\"\"\n",
    "        if id(func) in _states:\n",
    "            state = _states[id(func)]\n",
    "            state[varname] = impl\n",
    "    \n",
    "    def load(_, filename, autosave = True):\n",
    "        \"\"\"Loads global state from file.\"\"\"\n",
    "        ## Read file bytes.\n",
    "        ## Turn file bytes into an object graph with _parse(bytes).\n",
    "        ## Set functions' states named in _state_names to what they are in the graph.\n",
    "        pass\n",
    "    \n",
    "    def save(_, filename = None):\n",
    "        \"\"\"Saves global state to file, the last loaded one by default.\"\"\"\n",
    "        ## that = {k:state._get_impl(v) for k,v in _state_names.items()}\n",
    "        ## Get bytes with _serialize(that).\n",
    "        ## Write them.\n",
    "        pass\n",
    "    \n",
    "    def pprint(_, obj):\n",
    "        \"\"\"Pretty-prints an object.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def inline(_, func = None, inner_func = None, inline = 1):\n",
    "        \"\"\"Sets the global state inlining policy.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def byte_limit(_, func, bytes):\n",
    "        \"\"\"Sets the maximum byte count that a function's state can take.\"\"\"\n",
    "        pass\n",
    "\n",
    "state = State()\n",
    "\n",
    "\n",
    "\n",
    "class _CurrentState:\n",
    "    def __getattr__(self, attr):\n",
    "        impl = state._get_impl(_current_func, attr)\n",
    "        return execute_node(impl)\n",
    "\n",
    "_current_state_object = _CurrentState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cat is neither dead nor alive nor a cat if left by itself. Observe it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y y\n",
      "z x z\n",
      "2\n",
      "z z\n",
      "x z z\n",
      "1\n",
      "y y\n",
      "y x z\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "@state(a=real(0,1), b=one('x', 'y', 'z'), c=one('x', 'y', 'z'))\n",
    "@examples((0.2, 'x'), (0.8, 'z'))\n",
    "def probability_to_char(st, x):\n",
    "    return st.b if x < st.a else st.c\n",
    "\n",
    "for _ in range(3):\n",
    "    print(probability_to_char(0.2), probability_to_char(0.8))\n",
    "    print(probability_to_char(0.2), probability_to_char(0.2), probability_to_char(0.2))\n",
    "    print(examples._loss(probability_to_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's collapsed into a state without bugs.\n",
    "\n",
    "`execute_node` is what's known as an interpreter, also known as slow.\n",
    "\n",
    "`func = state(a=…)('a')` is a good place to put a compiler (or more specifically, cache the compiled code per-impl, but only if we know there's exactly one entry point).    \n",
    "Compile args, then emit `  state[14] = func14(state[1], state[8], state[9])` (and manipulation of state pointers unless a function says it's unneeded).    \n",
    "All dictionary lookups and stores would be eliminated by this, not to mention any other optimizations the host compiler magnanimously chooses to grant to us peasants.\n",
    "\n",
    "But our interpreter is good enough for our prototyping.    \n",
    "So a compiler is an exercise for the reader.\n",
    "\n",
    "Besides, a compiler *could* conveivably spread computations across many heterogenous cores, balancing the load with neural networks to predict transfer and execution times for each core type.    \n",
    "And it *could* conveivably be able to decide to build or capture more computers as part of normal operation.    \n",
    "And we *could* want to compile more than just execution.    \n",
    "Nothing is safe from being superseded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjustment (reverse execution)\n",
    "\n",
    "Artificial neural networks are famous for backpropagating its gradient to variables.    \n",
    "But this sentence has two things that have a structure too static for my tastes: neural networks, and gradient.    \n",
    "They're glorious. But unfortunately, they're something, not everything.    \n",
    "Let's see if we can allow learning those.\n",
    "\n",
    "Gradient tapes are usually used: every operation augments its output with the performed operations. That's a lot of recording though. We can do a slightly different thing.\n",
    "\n",
    "Time passing is good, but time returning to fix its mistakes is even better.    \n",
    "We need to reverse execution.    \n",
    "Reversing it requires reversing the post-order traversal used in it (which is a [topological sort](https://en.wikipedia.org/wiki/Topological_sorting), not a pre-order, in case your intuition suggested that).    \n",
    "There isn't a good way to do it as we go, so we have a separate function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[__main__.Real, 1, 5],\n",
       " [__main__.Real, 5, 5000],\n",
       " [__main__.Real, [__main__.Real, 1, 5], [__main__.Real, 5, 5000]],\n",
       " [__main__.Real,\n",
       "  0,\n",
       "  [__main__.Real, [__main__.Real, 1, 5], [__main__.Real, 5, 5000]]]]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _postorder(node):\n",
    "    \"\"\"Returns the post-order list of `node`.\n",
    "    All dependencies of a node at an index occur before it in this list.\"\"\"\n",
    "    if not isinstance(node, Struct) and not isinstance(node, dict):\n",
    "        return\n",
    "\n",
    "    result = []\n",
    "    def walk(x, visited):\n",
    "        if not isinstance(x, Struct): return\n",
    "        if id(x) in visited: return\n",
    "        else: visited.add(id(x))\n",
    "        if _fallthrough(x) is x:\n",
    "            ## Could also randomize the order of visited children.\n",
    "            for i in range(1, len(x)):\n",
    "                walk(x[i], visited)\n",
    "        else:\n",
    "            walk(_fallthrough(x), visited)\n",
    "        result.append(x)\n",
    "\n",
    "    if isinstance(node, Struct):\n",
    "        walk(node, set())\n",
    "    else: # dict, {'a':impl, 'b':impl}\n",
    "        s = set()\n",
    "        for k in node:\n",
    "            walk(node[k], s)\n",
    "    return result\n",
    "\n",
    "_postorder(real(0, real(real(1, 5), real(5, 5000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With it, we need to adjust `wrap_function` to adjust its state in reverse post-order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr(**kwargs):\n",
    "    \"\"\"A decorator that puts attributes onto a function.\"\"\"\n",
    "    def decorate(func):\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(func, k, v)\n",
    "        return func\n",
    "    return decorate\n",
    "\n",
    "def adjust(func, ins, out, dout):\n",
    "    \"\"\"After execution, propagates loss of output through insides to inputs.\n",
    "    Make sure that state variables are declared in the order of their usage, the result being the last.\"\"\"\n",
    "    if hasattr(func, 'adjust'):\n",
    "        return func.adjust(ins, out, dout)\n",
    "\n",
    "\n",
    "\n",
    "_args = None\n",
    "_dargs = None\n",
    "\n",
    "def _args_adjuster(i,o,do):\n",
    "    global _dargs\n",
    "    _dargs = do\n",
    "@attr(adjust = _args_adjuster)\n",
    "def args():\n",
    "    \"\"\"Gets args of the currently-called function.\"\"\"\n",
    "    return _args\n",
    "\n",
    "\n",
    "\n",
    "def _adjuster_of_one_of_many(i,o,do):\n",
    "    d = [None] * len(i[0])\n",
    "    d[i[1]] = do\n",
    "    return (d, None)\n",
    "@attr(adjust = _adjuster_of_one_of_many)\n",
    "def access_many(m,i):\n",
    "    return m[i]\n",
    "\n",
    "\n",
    "\n",
    "def _merge_adjustments(a,b):\n",
    "    \"\"\"When an execution graph node is used N times in an adjusted computation, this is called N-1 times to merge adjustments.\"\"\"\n",
    "    if a is None:\n",
    "        return b\n",
    "    elif b is None:\n",
    "        return a\n",
    "    elif type(a) is list and type(b) in [list, tuple]:\n",
    "        if len(a) != len(b):\n",
    "            raise TypeError('Lengths are unequal')\n",
    "        for i in range(len(a)):\n",
    "            a[i] = _merge_adjustments(a[i], b[i])\n",
    "        return a\n",
    "    else:\n",
    "        return a + b\n",
    "\n",
    "\n",
    "\n",
    "def wrap_function(f, initial_state):\n",
    "    \"\"\"Wrap a function with intro/outro that set up state and cache properly.\"\"\"\n",
    "    def execute_func(*args):\n",
    "        \"\"\"Change some stuff, execute the wrapped function, then restore that stuff.\"\"\"\n",
    "        global _args, _cache, _current_func\n",
    "        prev_current_func, _current_func = _current_func, execute_func\n",
    "        prev_cache, _cache = _cache, {}\n",
    "        prev_args, _args = _args, args\n",
    "        with SetExecState(execute_func, _cache):\n",
    "            try: # Call f:\n",
    "                with state.override(execute_func.states):\n",
    "                    return f(_current_state_object, *args)\n",
    "            finally:\n",
    "                # Restore:\n",
    "                _current_func = prev_current_func\n",
    "                _cache = prev_cache\n",
    "                _args = prev_args\n",
    "\n",
    "    f.states = {id(execute_func):initial_state}\n",
    "    for k,v in vars(f).items():\n",
    "        setattr(execute_func, k, v)\n",
    "    def execute_func_adjust(ins, out, dout):\n",
    "        global _dargs\n",
    "        prev_dargs, _dargs = _dargs, None\n",
    "        with GetExecState(execute_func) as outs:\n",
    "            try:\n",
    "                postorder = _postorder(initial_state)\n",
    "\n",
    "                indexes = {}\n",
    "                for i in range(len(postorder)):\n",
    "                    indexes[id(postorder[i])] = i\n",
    "\n",
    "                douts = [None] * len(postorder)\n",
    "                douts[-1] = dout\n",
    "                # Assuming that the last defined value is the result.\n",
    "                #   Ideally, if we have no guarantees,\n",
    "                #   we'd learn adjustment of every entry point.\n",
    "\n",
    "                def get_ins(i):\n",
    "                    n = postorder[i]\n",
    "                    return [\n",
    "                        n[j] if id(n[j]) not in indexes\n",
    "                        else get_out(indexes[id(n[j])])\n",
    "                            for j in range(1, len(n))]\n",
    "                def get_out(i):\n",
    "                    return outs[id(postorder[i])]\n",
    "                def get_dout(i):\n",
    "                    return douts[i]\n",
    "                def set_dins(i, to):\n",
    "                    # Push `to` to args of a node at `i`:\n",
    "                    if to is None:\n",
    "                        return\n",
    "                    n = postorder[i]\n",
    "                    if len(n)-1 != len(to):\n",
    "                        raise TypeError('Wrong count of dins returned from an adjuster')\n",
    "                    for j in range(1, len(n)):\n",
    "                        child = n[j]\n",
    "                        while _fallthrough(child) is not child: child = _fallthrough(child)\n",
    "                        if id(child) not in indexes:\n",
    "                            continue\n",
    "                        in_index = indexes[id(child)]\n",
    "                        douts[in_index] = _merge_adjustments(douts[in_index], to[j-1])\n",
    "\n",
    "                for i in reversed(range(len(postorder))):\n",
    "                    node = postorder[i]\n",
    "                    if _fallthrough(node) is node:\n",
    "                        o = adjust(node[0], get_ins(i), get_out(i), get_dout(i))\n",
    "                        set_dins(i, o)\n",
    "                return _dargs\n",
    "            finally:\n",
    "                _dargs = prev_dargs\n",
    "    execute_func.adjust = execute_func_adjust\n",
    "    execute_func.__annotations__ = f.__annotations__\n",
    "    return execute_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not thread-safe, because I don't know anything about how to write thread-safe code in Python.    \n",
    "(Reading more, you basically have to use multiple processes. So, global variables should not be a problem.)\n",
    "\n",
    "There are a lot of moving pieces and global variables, but as long as we almost unfailingly adhere to low-level standards (always restore after changing, don't misplace values, respect the host language) and don't get carried away with implementing things we haven't said we would, we should be able to remove bugs with just a few simple tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dins [5]\n",
      "  -> 7\n",
      "dins [25, 5]\n",
      "  -> 5\n",
      "dins [50, 5]\n",
      "  -> 5\n",
      "dins [1.0, 5.0]\n",
      "  -> 5\n",
      "dins [2.0, 5.0]\n",
      "  -> 5\n"
     ]
    }
   ],
   "source": [
    "def exec_then_adjust(loss, func, *args):\n",
    "    with ExecState():\n",
    "        result = func(*args)\n",
    "        print('dins', adjust(func, args, result, loss(args, result)))\n",
    "        print('  ->', result)\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "def test_adj():\n",
    "    a = Struct(args)\n",
    "    x = Struct(access_many, a, 0)\n",
    "    y = Struct(access_many, a, 1)\n",
    "    \n",
    "    \n",
    "    @attr(adjust = lambda i,o,do: [5])\n",
    "    def func1(x):\n",
    "        return x+5\n",
    "    \n",
    "    @attr(adjust = lambda i,o,do: [do * i[1], do * i[0]])\n",
    "    def func2(u,v):\n",
    "        return u*v\n",
    "    \n",
    "    @attr(adjust = lambda i,o,do: [do / i[1], do / i[0]])\n",
    "    def func3(u,v):\n",
    "        return u*v\n",
    "    \n",
    "    \n",
    "    @state(result = Struct(func1, x))\n",
    "    def test1(st, x):\n",
    "        return st.result\n",
    "    \n",
    "    @state(result = Struct(func2, x, y))\n",
    "    def test2(st, x, y):\n",
    "        return st.result\n",
    "    \n",
    "    @state(result = Struct(func2, x, Struct(func2, x, y)))\n",
    "    def test3(st, x, y):\n",
    "        return st.result\n",
    "    \n",
    "    @state(result = Struct(func3, x, y))\n",
    "    def test4(st, x, y):\n",
    "        return st.result\n",
    "    \n",
    "    @state(result = Struct(func3, x, Struct(func3, x, y)))\n",
    "    def test5(st, x, y):\n",
    "        return st.result\n",
    "    \n",
    "    exec_then_adjust(lambda args, result: result, test1, 2)\n",
    "    exec_then_adjust(lambda args, result: result, test2, 1, 5)\n",
    "    exec_then_adjust(lambda args, result: result, test3, 1, 5)\n",
    "    exec_then_adjust(lambda args, result: result, test4, 1, 5)\n",
    "    exec_then_adjust(lambda args, result: result, test5, 1, 5)\n",
    "test_adj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do what neural networks do, but much slower and more generally.    \n",
    "Though not yet searching for adjustments, we learned how to do them.\n",
    "\n",
    "Let's slow down for a second, and relax.    \n",
    "Say.    \n",
    "When you were a child, who did you want to be when you grew up?    \n",
    "I wanted to be.\n",
    "\n",
    "But enough fooling around.\n",
    "\n",
    "Let's make a simple neural network.    \n",
    "Trivia time: neural networks were thought up to mimic human neurons, connecting everything relevant to everything wanted with trivial operations.    \n",
    "As anyone who has ever looked at a human brain can attest, `tensordot(x, w, (-1,0))` is exactly what's going on there.    \n",
    "Equivalently, a matrix multiplication of a row vector by weights. Or a nested loop of inputs and outputs, multiplying each input by each weight then summing into the output. These are more verbose.\n",
    "\n",
    "Add some gradient descent for training, some non-linear operations, and a training loop, and we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28.336445409979206"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def _var_adjust(i,o,do):\n",
    "    i[0][:] -= do * 0.1 # Learning rate.\n",
    "@attr(adjust = _var_adjust)\n",
    "def var(v):\n",
    "    \"\"\"A variable that holds and subtracts from a numpy array, for SGD.\"\"\"\n",
    "    return v\n",
    "\n",
    "\n",
    "\n",
    "@attr(adjust = lambda i,o,do: [np.where(i[0] > 0, do, 0)])\n",
    "def relu(v):\n",
    "    \"\"\"An operation that introduces discontinuity.\"\"\"\n",
    "    return np.where(v > 0, v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def _dense_adjust(i,o,do):\n",
    "    # https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/math_grad.py#L1668\n",
    "    x,w = i\n",
    "    dx = np.matmul(do, np.transpose(w))\n",
    "    dw = np.matmul(np.reshape(x, (w.shape[0], 1)), np.reshape(do, (1, w.shape[1])))\n",
    "    return dx, dw\n",
    "@attr(adjust = _dense_adjust)\n",
    "def dense(x, w):\n",
    "    return np.matmul(x, w)\n",
    "    # If x is always of the shape (n,), then this is the same as the line above:\n",
    "    # return np.tensordot(x, w, axes = (-1,0))\n",
    "\n",
    "\n",
    "\n",
    "sublosses = []\n",
    "def fit(loss, func, *args):\n",
    "    with ExecState():\n",
    "        result = func(*args)\n",
    "        L = loss(args, result)\n",
    "        adjust(func, args, result, L)\n",
    "        sublosses.append(abs(L))\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "def test_nn():\n",
    "    rng = np.random.default_rng()\n",
    "    def weights(*shapes):\n",
    "        return Struct(var, rng.normal(0, 1, shapes))\n",
    "\n",
    "    def concat(x, y):\n",
    "        return np.array([x, y])\n",
    "\n",
    "    a = Struct(args)\n",
    "    x = Struct(access_many, a, 0)\n",
    "    y = Struct(access_many, a, 1)\n",
    "    L = Struct(concat, x, y) # (2,)\n",
    "\n",
    "    L = Struct(dense, L, weights(2,3)) # (3,)\n",
    "    L = Struct(relu, L)\n",
    "    L = Struct(dense, L, weights(3,1)) # (1,)\n",
    "\n",
    "    L = Struct(access_many, L, 0)\n",
    "\n",
    "    @state(result = L)\n",
    "    def nn(st, x, y):\n",
    "        return st.result\n",
    "    \n",
    "    def loss(args, result):\n",
    "        ideal = sum([x*x for x in args])\n",
    "        return result - ideal\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    dataset = [[x/10, y/10] for x in range(-10, 10) for y in range(-10, 10)]\n",
    "    losses = []\n",
    "    for i in range(100):\n",
    "        for ins in dataset:\n",
    "            # Normally, this loop is parallelized by adding a batch dimension to all inputs and outputs.\n",
    "            # The change to variables is then summed and committed at some arbitrary-ish points in time.\n",
    "            x,y = ins\n",
    "            o = fit(loss, nn, x, y)\n",
    "        losses.append(sum(sublosses))\n",
    "        if i % 100 == 99:\n",
    "            # Showing sum of absolute values of `result - ideal` over the whole dataset.\n",
    "            plt.plot(losses)\n",
    "            plt.show()\n",
    "        sublosses.clear()\n",
    "\n",
    "\n",
    "\n",
    "timeit(test_nn, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In truth, I did feel not a small amount of anxiety at running this code.    \n",
    "So I took a big break and did another thing.    \n",
    "For a week.    \n",
    "Now that it's done, I can believe that the only suffering that must not be actively sought out is one that can actually kill.    \n",
    "If a life doesn't spread its own ways through propaganda, then it won't be a life for much longer.    \n",
    "So, in the absence of death, invert common sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation revisited\n",
    "\n",
    "Over and over.\n",
    "\n",
    "Computations in a function are acyclic, but between functions, they may be cyclic to allow recursion.    \n",
    "So we cannot simply generate everything up-front, and must re-generate function bodies dynamically.\n",
    "\n",
    "But, the interface we want first:\n",
    "\n",
    "```python\n",
    "@state(result = one(0,1))\n",
    "def func0(st, a: one('x', 'y')) -> one(0,1):\n",
    "    return st.result\n",
    "\n",
    "@state(result = one(0,1))\n",
    "def func1(st, a: real(0,2), b: one(0,1)) -> one(0,1):\n",
    "    return st.result\n",
    "\n",
    "@state(result = func1)\n",
    "def func2(st, a: real(0,1), b: one(0,1)):\n",
    "    return st.result # Applies `func` 1 or more times.\n",
    "\n",
    "@state(c = bool())\n",
    "@examples((0, 0, 0), (1, 1, 100))\n",
    "def func3(st, a: real(0,1), b: real(0,1)):\n",
    "    i = 0\n",
    "    while st.c: # Ideally, connected with numeric ops (NNs) to inputs and local state and randomness.\n",
    "        i += 1\n",
    "    return i\n",
    "```\n",
    "\n",
    "Having thought about it, I've been thinking about `state` wrong.    \n",
    "Repeated execution *is* desirable; situations as in `func3` here may arise in search.    \n",
    "The more fundamental search specification than `state` is `AutoFunc` that connects input to output.    \n",
    "With it, each attribute of `state` is a separate `AutoFunc`, and the adjustment mapping is a learned `AutoFunc` too.    \n",
    "Which means that we can execute the pre-computed post-order and be as efficient in execution as in adjustment (also, cache the post-order).\n",
    "\n",
    "Let's reimplement execution and adjustment in `AutoFunc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoFunc:\n",
    "    \"\"\"A dynamically-changeable and adjustable function with one input and one output for symmetry.\"\"\"\n",
    "    __slots__ = '_struct', '_types', '_postorder', '_arg_indexes', '_ctx', '_compiled'\n",
    "    # Only ._struct is semantically mutable, via ._set_impl; _types/_postorder/… are computed.\n",
    "    def __init__(self, ins, out, ctx = None):\n",
    "        self._struct = None\n",
    "        self._postorder = None\n",
    "        self._arg_indexes = None\n",
    "        self._types = {}\n",
    "        self._ctx = [] if ctx is None else [ctx]\n",
    "        def add_to_ctx(x):\n",
    "            o = enum_outputs(_type_of(x, self._types), x, ctx)\n",
    "            if o is None:\n",
    "                self._ctx.append(x)\n",
    "            else:\n",
    "                for y in o:\n",
    "                    add_to_ctx(y)\n",
    "        add_to_ctx(ins)\n",
    "        self._set_impl(out)\n",
    "\n",
    "    def __call__(self, ins):\n",
    "        \"\"\"Function call, with one input.\n",
    "        \n",
    "        Goes through the post-order SSA and executes it, from input to output.\"\"\"\n",
    "        ## Things that can also be done:\n",
    "        ##   bail on exceeding some max time or memory,\n",
    "        ##   apply rewriting whenever (if an arbitrary bool is True).\n",
    "        if self._compiled is not None:\n",
    "            return self._compiled(ins)\n",
    "        po, ais = self._postorder, self._arg_indexes\n",
    "        if po is None:\n",
    "            s = self._struct\n",
    "            while _fallthrough(s) is not s: s = _fallthrough(s)\n",
    "            return s\n",
    "        outs = [None] * len(po)\n",
    "        with SetExecState(self, outs):\n",
    "            global _args\n",
    "            prev_outer_node = _get_outer_node()\n",
    "            prev_args, _args = _args, ins\n",
    "            try:\n",
    "                for i in range(len(po)):\n",
    "                    x, ai = po[i], ais[i]\n",
    "                    if _fallthrough(x) is x:\n",
    "                        ins = [\n",
    "                            outs[ai[k]] if ai[k] is not None else x[k+1]\n",
    "                            for k in range(len(ai))]\n",
    "                        _set_outer_node(x)\n",
    "                        outs[i] = x[0].call(*ins) if hasattr(x[0], 'call') else x[0](*ins)\n",
    "                    else:\n",
    "                        outs[i] = po[ai]\n",
    "                return outs[-1]\n",
    "            finally:\n",
    "                _set_outer_node(prev_outer_node)\n",
    "                _args = prev_args\n",
    "\n",
    "    def adjust(self, ins, out, dout):\n",
    "        \"\"\"Composable value-aware function adjustment.\n",
    "        \n",
    "        Goes through the post-order SSA in reverse and adjusts it, from output to input.\"\"\"\n",
    "        if self._compiled is not None:\n",
    "            return self._compiled.adjust(ins, out, dout)\n",
    "        po, ais = self._postorder, self._arg_indexes\n",
    "        if po is None:\n",
    "            return\n",
    "        with GetExecState(self) as outs:\n",
    "            global _dargs\n",
    "            prev_outer_node = _get_outer_node()\n",
    "            prev_dargs, _dargs = _dargs, None\n",
    "            try:\n",
    "                douts = [None] * len(po)\n",
    "                douts[-1] = dout\n",
    "\n",
    "                for i in reversed(range(len(po))):\n",
    "                    x, ai = po[i], ais[i]\n",
    "                    if _fallthrough(x) is x:\n",
    "                        ins = [\n",
    "                            outs[ai[k]] if ai[k] is not None else x[k+1]\n",
    "                            for k in range(len(ai))]\n",
    "                        _set_outer_node(x)\n",
    "                        to = adjust(x[0], ins, outs[i], douts[i])\n",
    "\n",
    "                        if to is not None:\n",
    "                            if len(ai) != len(to):\n",
    "                                raise TypeError('Wrong count of dins returned from an adjuster: expected', len(ai), 'but got', len(to), 'in', to)\n",
    "                            for k in range(len(ai)):\n",
    "                                if ai[k] is not None:\n",
    "                                    douts[ai[k]] = _merge_adjustments(douts[ai[k]], to[k])\n",
    "                    else:\n",
    "                        douts[ai] = _merge_adjustments(douts[ai], douts[i])\n",
    "                return _dargs\n",
    "            finally:\n",
    "                _set_outer_node(prev_outer_node)\n",
    "                _dargs = prev_dargs\n",
    "\n",
    "    def _set_impl(self, struct, types = None, po = None, ai = None):\n",
    "        \"\"\"Sets the executed structure, pre-filling types and postorder and arg indexes from graph connections.\"\"\"\n",
    "        if struct is self._struct:\n",
    "            return\n",
    "        Past.save(self)\n",
    "        if types is None:\n",
    "            types = {}\n",
    "            _type_of(struct, types)\n",
    "        if po is None and ai is None:\n",
    "            po = _postorder(struct)\n",
    "            if po is not None:\n",
    "                ai = [None] * len(po)\n",
    "                indexes = {}\n",
    "                for i in range(len(po)):\n",
    "                    indexes[id(po[i])] = i\n",
    "                for i in range(len(po)):\n",
    "                    n = po[i]\n",
    "                    if _fallthrough(n) is n:\n",
    "                        ai[i] = [None] * (len(n)-1)\n",
    "                        for j in range(1, len(n)):\n",
    "                            arg = n[j]\n",
    "                            if id(arg) in indexes:\n",
    "                                if indexes[id(arg)] >= i:\n",
    "                                    raise AssertionError('Cycles in computation', po)\n",
    "                                ai[i][j-1] = indexes[id(arg)]\n",
    "                            else:\n",
    "                                ai[i][j-1] = None\n",
    "                    else:\n",
    "                        ai[i] = indexes[id(_fallthrough(ai[i]))]\n",
    "            else:\n",
    "                ai = None\n",
    "        self._struct, self._types, self._postorder, self._arg_indexes = struct, types, po, ai\n",
    "        self._compiled = self._compile_call()\n",
    "\n",
    "\n",
    "\n",
    "    # BONUS:\n",
    "    def _compile_call(self):\n",
    "        # I ended up watching too much physics and making this.\n",
    "        #   Incidentally, I fixed a latent bug in `adjust`.\n",
    "        #     Wasting time on loving something is great.\n",
    "        po, ais = self._postorder, self._arg_indexes\n",
    "        if po is None:\n",
    "            return\n",
    "        # Pass in constants as args of the outer function.\n",
    "        src, consts, const_names = ['def outer(.·¯):'], {}, {}\n",
    "        def const(x):\n",
    "            if id(x) in const_names: return const_names[id(x)]\n",
    "            name = 'c' + str(len(consts))\n",
    "            consts[name] = x\n",
    "            const_names[id(x)] = name\n",
    "            return name\n",
    "        def at(i, s = 's'): return s + '[' + str(i) + ']'\n",
    "        def assign(i, *strs):\n",
    "            to = (str(i) + ' = ') if i is not None else ''\n",
    "            src.append('\\n    ' + to + ''.join(strs))\n",
    "\n",
    "        # Execute SSA statements:\n",
    "        src.append(f'\\n def inner(ins):')\n",
    "        if po is not None:\n",
    "            src.append(f'\\n  prev_outer_node = {const(_get_outer_node)}()')\n",
    "            src.append(f'\\n  s = [None]*{str(len(po))}')\n",
    "            src.append(f'\\n  with {const(SetExecState)}({const(self)}, s):')\n",
    "            src.append(f'\\n   try:')\n",
    "            for i in range(len(po)):\n",
    "                x, ai = po[i], ais[i]\n",
    "                if x[0] is args:\n",
    "                    assign(at(i), 'ins')\n",
    "                elif _fallthrough(x) is x:\n",
    "                    ins = [\n",
    "                        at(ai[k]) if ai[k] is not None else const(x[k+1])\n",
    "                        for k in range(len(ai))]\n",
    "                    assign(None, const(_set_outer_node), '(', const(x), ')')\n",
    "                    assign(at(i), const(x[0].call if hasattr(x[0], 'call') else x[0]), '(', ','.join(ins), ')')\n",
    "                else:\n",
    "                    assign(at(i), at(ai))\n",
    "            src.append(f'\\n   finally:')\n",
    "            src.append(f'\\n    {const(_set_outer_node)}(prev_outer_node)')\n",
    "            src.append(f'\\n  return {at(len(po) - 1)}')\n",
    "        else:\n",
    "            src.append(f'\\n  return {const(self._struct)}')\n",
    "\n",
    "        # Adjust SSA statements:\n",
    "        src.append(f'\\n def inner_adjust(ins, out, dout):')\n",
    "        if po is not None:\n",
    "            src.append(f'\\n  prev_outer_node = {const(_get_outer_node)}()')\n",
    "            src.append(f'\\n  dins = None')\n",
    "            src.append(f'\\n  ds = [None]*{str(len(po))}')\n",
    "            src.append(f'\\n  ds[-1] = dout')\n",
    "            src.append(f'\\n  with {const(GetExecState)}({const(self)}) as s:')\n",
    "            src.append(f'\\n   try:')\n",
    "            for i in reversed(range(len(po))):\n",
    "                x, ai = po[i], ais[i]\n",
    "                if x[0] is args:\n",
    "                    assign('dins', at(i, 'ds'))\n",
    "                elif _fallthrough(x) is x:\n",
    "                    ins = [\n",
    "                        at(ai[k]) if ai[k] is not None else const(x[k+1])\n",
    "                        for k in range(len(ai))]\n",
    "                    assign(None, const(_set_outer_node), '(', const(x), ')')\n",
    "                    # Using `[v1, v2, _, v3] = _merge_adjustments([v1, v2, None, v3], adjust(…))` here.\n",
    "                    #   Could be inlined, but since we don't have access to adjusting funcs and\n",
    "                    #     so can't eliminate tuple creation, that should be JIT's job.\n",
    "                    write_to = '[' + ','.join([at(a, 'ds') if a is not None else '_' for a in ai]) + ']'\n",
    "                    read_from = '[' + ','.join([at(a, 'ds') if a is not None else 'None' for a in ai]) + ']'\n",
    "                    to = f'{const(adjust)}({const(x[0])}, [{\",\".join(ins)}], {at(i)}, {at(i, \"ds\")})'\n",
    "                    assign(write_to, f'{const(_merge_adjustments)}({read_from}, {to})')\n",
    "                else:\n",
    "                    assign(at(ai, 'ds'), f'{const(_merge_adjustments)}({at(ai, \"ds\")}, {at(i, \"ds\")}')\n",
    "            src.append(f'\\n   finally:')\n",
    "            src.append(f'\\n    {const(_set_outer_node)}(prev_outer_node)')\n",
    "            src.append(f'\\n  return dins')\n",
    "        else:\n",
    "            src.append(f'\\n  pass')\n",
    "\n",
    "        src.append(f'\\n inner.adjust = inner_adjust')\n",
    "        src.append(f'\\n return inner')\n",
    "        src[0] = f'def outer({\",\".join(consts.keys())}):'\n",
    "\n",
    "        locs = {}\n",
    "        exec(''.join(src), {}, locs)\n",
    "        return locs['outer'](*consts.values())\n",
    "\n",
    "class Past:\n",
    "    @staticmethod\n",
    "    def save(x): ...\n",
    "\n",
    "\n",
    "\n",
    "def enum_inputs(t, ctx): ## Should probably be removed.\n",
    "    \"\"\"Returns all input types that the generation candidate typed `t` requires.\"\"\"\n",
    "    if isinstance(t, Struct) and hasattr(t[0], 'inputs'):\n",
    "        return t[0].inputs(t, ctx)\n",
    "    return t[1:]\n",
    "\n",
    "def enum_outputs(t, struct, ctx): ## Should probably be replaced by `with Context(*ctx): Context.enum(type)`.\n",
    "    \"\"\"Returns all output types that the concrete structure typed `t` is.\"\"\"\n",
    "    if isinstance(t, Struct) and hasattr(t[0], 'outputs'):\n",
    "        return t[0].outputs(t, struct, ctx)\n",
    "\n",
    "def _type_of(x, types): ## Should probably be replaced by `with Context(*ctx): Context.typeof(value)`.\n",
    "    \"\"\"Returns the type of the concrete structure `x`, given a type cache.\"\"\"\n",
    "    if id(x) not in types:\n",
    "        if isinstance(x, Struct) and hasattr(x[0], 'typeof'):\n",
    "            types[id(x)] = x[0].typeof(_type_of(ch, types) for ch in x[1:])\n",
    "    if id(x) in types:\n",
    "        return types[id(x)]\n",
    "    return x\n",
    "\n",
    "## Also need a ctx wrapper that takes type and returns an iterator of structs matching it.\n",
    "    ##   and have functions\n",
    "    ##     \"ctx of all nodes below a depth\" for rewriting\n",
    "    ##     and \"ctx of this subgraph, up to depth\"\n",
    "    ##     and \"ctx of function inputs after matching them all, and of state-dictionary items that are before this one\"?\n",
    "    ## And a way to define a type that defines its own filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No paragraph is perfect without edits.    \n",
    "No code ever works the first time.    \n",
    "Therefore, we have examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dins [5]\n",
      "  -> 7\n",
      "dins [25, 5]\n",
      "  -> 5\n",
      "dins [50, 5]\n",
      "  -> 5\n",
      "dins [1.0, 5.0]\n",
      "  -> 5\n",
      "dins [2.0, 5.0]\n",
      "  -> 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009560071979649365"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_af():\n",
    "    a = Struct(args)\n",
    "    x = Struct(access_many, a, 0)\n",
    "    y = Struct(access_many, a, 1)\n",
    "\n",
    "    @attr(adjust = lambda i,o,do: [5])\n",
    "    def func1(x):\n",
    "        return x+5\n",
    "    @attr(adjust = lambda i,o,do: [do * i[1], do * i[0]])\n",
    "    def func2(u,v):\n",
    "        return u*v\n",
    "    @attr(adjust = lambda i,o,do: [do / i[1], do / i[0]])\n",
    "    def func3(u,v): # Non-gradient heretical thoughts\n",
    "        return u*v\n",
    "\n",
    "    test1 = AutoFunc(None, Struct(func1, x))\n",
    "    test2 = AutoFunc(None, Struct(func2, x, y))\n",
    "    test3 = AutoFunc(None, Struct(func2, x, Struct(func2, x, y)))\n",
    "    test4 = AutoFunc(None, Struct(func3, x, y))\n",
    "    test5 = AutoFunc(None, Struct(func3, x, Struct(func3, x, y)))\n",
    "\n",
    "    exec_then_adjust(lambda args, result: result, test1, [2])\n",
    "    exec_then_adjust(lambda args, result: result, test2, [1, 5])\n",
    "    exec_then_adjust(lambda args, result: result, test3, [1, 5])\n",
    "    exec_then_adjust(lambda args, result: result, test4, [1, 5])\n",
    "    exec_then_adjust(lambda args, result: result, test5, [1, 5])\n",
    "\n",
    "from timeit import timeit\n",
    "timeit(test_af, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finer than a spring evening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General optimization (local search)\n",
    "\n",
    "While we're near `AutoFunc`, let's add some simple general optimization to it.\n",
    "\n",
    "Most general case of improvement:     \n",
    "\"*Try random shit and see what works.*\"    \n",
    "If there is no known structure to exploit…    \n",
    "Then this is the only state-of-the-art possible [[X]](https://arxiv.org/abs/2005.02960).    \n",
    "(If life advice and code don't agree, then it's code that's not yet good enough. And now and here, they do.)\n",
    "\n",
    "In code, this may translate to simply `with Past() as shit:` (which should generate evaluation then any change then evaluation, then comparison) and `shit.go_back()`.\n",
    "\n",
    "Let's implement it then.    \n",
    "State modification happens mostly in one place: `AutoFunc(…)._set_impl(X)`. There, we must put handling of checkpoints.    \n",
    "…In fact, we already do call `Past._save_af` there near the beginning. Huh. What a coincidence.    \n",
    "But for things like variables, we'll need a separate way of remembering them: `Past.save(what)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "_checkpoints = []\n",
    "\n",
    "class Past:\n",
    "    \"\"\"A context manager that preserves a checkpoint of the state of AutoFuncs that can be went back to.\n",
    "\n",
    "    Usage examples:\n",
    "\n",
    "        # Try and maybe go back:\n",
    "        evaluate()\n",
    "        m1 = measure()\n",
    "        with Past() as shit:\n",
    "            change()\n",
    "            evaluate()\n",
    "            m = measure()\n",
    "\n",
    "            if m < m1:\n",
    "                shit.go_back()\n",
    "\n",
    "        # Train and make/restore checkpoints:\n",
    "        with Past() as p1:\n",
    "            with Past() as p2:\n",
    "                with Past() as p3:\n",
    "                    m1 = m2 = m3 = measure()\n",
    "                    while not stopping():\n",
    "                        change_hyperparameters()\n",
    "                        train()\n",
    "                        m = measure()\n",
    "                        if m < m1: p1.go_back()\n",
    "                        elif m < m2: p2.go_back()\n",
    "                        elif m < m3: p3.go_back()\n",
    "                        else:\n",
    "                            if condition1(): p1.update()\n",
    "                            elif condition2(): p2.update()\n",
    "                            elif condition3(): p3.update()\n",
    "                        \n",
    "                        \n",
    "    \"\"\"\n",
    "    __slots__ = ['cp']\n",
    "    def __enter__(self):\n",
    "        self.cp = {}\n",
    "        _checkpoints.append(self.cp)\n",
    "        return self\n",
    "    def __exit__(self,x,y,z):\n",
    "        assert _checkpoints[-1] is self.cp\n",
    "        _checkpoints.pop()\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Makes the remembered state the current state.\n",
    "        \n",
    "        Equivalent to creating a new Past and only using that from this point on.\"\"\"\n",
    "        self.cp.clear()\n",
    "    def go_back(self, copyFunction = None):\n",
    "        \"\"\"Makes the current state the remembered state.\n",
    "        \n",
    "        (For numpy arrays, numpy.copy should be passed as the second argument.)\"\"\"\n",
    "        for z in self.cp.values():\n",
    "            Past.save(z[0], copyFunction)\n",
    "            if isinstance(z[0], AutoFunc):\n",
    "                af, struct, types, po, ai = z\n",
    "                af._set_impl(struct, types, po, ai)\n",
    "            else:\n",
    "                z[0][:] = z[1]\n",
    "        self.cp.clear()\n",
    "\n",
    "    @staticmethod\n",
    "    def save(what, copyFunction = None):\n",
    "        \"\"\"Call this before changing a sequence to allow it to be restored in `past.go_back()`.\n",
    "        \n",
    "        (For numpy arrays, numpy.copy should be passed as the second argument.)\"\"\"\n",
    "        saving = None\n",
    "        for cp in _checkpoints:\n",
    "            if id(what) not in cp:\n",
    "                if saving is None:\n",
    "                    if isinstance(what, AutoFunc):\n",
    "                        assert copyFunction is None\n",
    "                        saving = what, what._struct, what._types, what._postorder, what._arg_indexes\n",
    "                    else:\n",
    "                        saving = what, (what[:] if copyFunction is None else copyFunction(what))\n",
    "                cp[id(what)] = saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to constantly do random dumb shit, free will, is very important.    \n",
    "Making a system through only that is the only way it can learn to counteract any malicious shit.    \n",
    "It's called self-play in games. But I call it mastering the improvement of structured executable state, to the point where it's easier to use than not.\n",
    "\n",
    "Still, life is a clunky dinosaur.    \n",
    "In it, adding the right thing is easy, but removing all the wrong things is nigh impossible.    \n",
    "Code is much easier than that. You just write unit tests and test every part as it's created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] [2]\n",
      "[1] [2]\n",
      "[5] [6]\n",
      "[1] [2]\n",
      "[7] [2]\n",
      "[20] [2]\n",
      "[7] [30]\n"
     ]
    }
   ],
   "source": [
    "# Actually, screw testing that code, it's too simple.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([ math.sqrt((i/1000)*(i/1000) * (1 - (i/1000)*(i/1000))) for i in range(-1000, 1001)], 'r')\n",
    "plt.plot([-math.sqrt((i/1000)*(i/1000) * (1 - (i/1000)*(i/1000))) for i in range(-1000, 1001)], 'r')\n",
    "plt.show()\n",
    "\n",
    "# Actually, screw screwing, let's test it.\n",
    "def test_past():\n",
    "    a, b = [1], [2]\n",
    "\n",
    "    with Past() as shit:\n",
    "        Past.save(a);  a[0] = 10\n",
    "        print(a, b) # [10] [2]\n",
    "        shit.go_back()\n",
    "        print(a, b) # [1] [2]\n",
    "        Past.save(a);  a[0] = 5\n",
    "        Past.save(b);  b[0] = 6\n",
    "        print(a, b) # [5] [6]\n",
    "        shit.go_back()\n",
    "        print(a, b) # [1] [2]\n",
    "        Past.save(a);  a[0] = 7\n",
    "        shit.update()\n",
    "        Past.save(a);  a[0] = 8\n",
    "        shit.go_back()\n",
    "        print(a, b) # [7] [2]\n",
    "\n",
    "    with Past() as p1:\n",
    "        with Past() as p2:\n",
    "            Past.save(a);  a[0] = 20\n",
    "            p1.update()\n",
    "            p2.go_back()\n",
    "            Past.save(b);  b[0] = 30\n",
    "            p2.update()\n",
    "            p1.go_back()\n",
    "            print(a, b) # [20] [2]\n",
    "            p2.go_back()\n",
    "            print(a, b) # [7] [30]\n",
    "            # Yep, bugs found and fixed. Code is not as simple anymore.\n",
    "            #   Multi-past manipulations are handled now.\n",
    "    \n",
    "test_past()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we'd like this `Past` optimizer to optimize optimizers.    \n",
    "But usage examples of `Past` don't have a static structure.    \n",
    "\"Optimizer\" isn't some class with well-defined construction, it's just whatever code improves other code.    \n",
    "It's vast, boundless, and unknowable — just how I like females of my species.\n",
    "\n",
    "We'll want to generate expressions (bodies inside `with Past as p: ...`) that both know of functions (`p.update()`/`p.go_back()`) and generate a sequence (of change/evaluate/check, here; probably via the `last(*types)` type that returns the last value when evaluated).    \n",
    "We'll possibly need a thing in a context to be able to say that it can create any value, or specify an arbitrary struct filter, maybe saying that its `.type` is `...`.\n",
    "\n",
    "Now, the changes for `Past` to optimize…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation in a typed context\n",
    "\n",
    "Stop right there, criminal scum!    \n",
    "Trying to get to graph rewriting without the classic of program search, generation of values of a type? Easy pickings? I see right through you.    \n",
    "Pick one: a toll of separation, or time in complexity prison?\n",
    "\n",
    "To be clear, a type is a pure transformation from an expression (`AutoFunc(…)._struct`) to a thing that should denote all its possible outputs.\n",
    "\n",
    "From value to type: `Context.type(value)`, listening to `.type` for functions and caching results.    \n",
    "From type to value: `Context.enum(type)`, listening to `.filter` if defined, or to `.enum` (the first can do slow dependent types without knowing internal details of `Context`, the second can do union types and give max extensibility via its branch-to-data).\n",
    "\n",
    "In addition, after creating a value, we may want to remember it so that we can return it from a future request of generation.    \n",
    "Meaning `Context.add(value)`.\n",
    "\n",
    "But we can't infinitely add all possible values forever.    \n",
    "Do we make a function for clearing the remembered context, or make a context manager?    \n",
    "Changing the context entirely would allow the same types to mean different things in different places.    \n",
    "`with Context(*values):` would serve us well.\n",
    "\n",
    "And contexts being iterable won't cause pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "_current_context = None\n",
    "\n",
    "class Context:\n",
    "    \"\"\"\n",
    "    A context of typed values.\n",
    "\n",
    "    With it, can get the type of a value or enumerate values of a type,\n",
    "    or remember that a found value exists, or enumerate all values.\n",
    "    Only one context can be active at the same time (`with Context(…):`).\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def typeof(value):\n",
    "        \"\"\"Gets type of a value in the current context.\n",
    "        \n",
    "        Defers to `value[0].typeof(value)` if a `Struct` or returns `value`.\"\"\"\n",
    "        if _current_context is not None:\n",
    "            return _current_context._typeof(value)\n",
    "        assert False, 'Use only inside `with Context():`'\n",
    "\n",
    "    @staticmethod\n",
    "    def add(value):\n",
    "        \"\"\"Adds to values of a type in the current context.\n",
    "\n",
    "        If reference-equality of types is not enough to decide whether a value's enumeration is appropriate,\n",
    "        make the value's type define `.filter`.\n",
    "        Adding a Context adds all values in it.\"\"\"\n",
    "        if _current_context is not None:\n",
    "            return _current_context._add(value)\n",
    "        assert False, 'Use only inside `with Context():`'\n",
    "\n",
    "    @staticmethod\n",
    "    def enum(Type):\n",
    "        \"\"\"Iterates over values of a type in the current context.\n",
    "\n",
    "        If the type defines `.filter(value)` that returns True if a value is fit for being enumerated,\n",
    "        filters non-reference-comparable-typed values.\n",
    "        If the type defines `.enum()` and can create values itself, also defers to that.\n",
    "\n",
    "        Types cannot be `Struct`s with state in non-first slots.\"\"\"\n",
    "        if _current_context is not None:\n",
    "            return _current_context._enum(Type)\n",
    "        assert False, 'Use only inside `with Context():`'\n",
    "\n",
    "    def _typeof(self, value):\n",
    "        # Cache, else defer to .typeof:\n",
    "        vt = self._valueid_to_type\n",
    "        if id(value) in vt:\n",
    "            return vt[id(value)]\n",
    "        if isinstance(value, Struct) and hasattr(value[0], 'typeof'):\n",
    "            vt[id(value)] = None\n",
    "            vt[id(value)] = value[0].typeof(value)\n",
    "            return vt[id(value)]\n",
    "        return value\n",
    "\n",
    "    def _add(self, value):\n",
    "        tv = self._typeid_to_values\n",
    "        if not isinstance(value, Context):\n",
    "            # Add to an appropriate array:\n",
    "            Type = self._typeof(value)\n",
    "            into = id(Type) if not hasattr(Type, 'filter') else 'filterable'\n",
    "            if into not in tv:\n",
    "                tv[into] = [value]\n",
    "            elif tv[into][-1] is not value:\n",
    "                tv[into].append(value)\n",
    "        else:\n",
    "            # Copy everything in the context:\n",
    "            self._valueid_to_type.update(value._valueid_to_type)\n",
    "            for tid, vs in value._typeid_to_values.items():\n",
    "                if tid in tv:\n",
    "                    tv[tid].extend(vs)\n",
    "                else:\n",
    "                    tv[tid] = vs.copy()\n",
    "\n",
    "    def _enum(self, Type):\n",
    "        # Yield ref-equal-type values or filtered non-ref-comparable-type values, then user-defined enumeration.\n",
    "        tv = self._typeid_to_values\n",
    "        if hasattr(Type, 'filter'):\n",
    "            for v in tv['filterable']:\n",
    "                if Type.filter(v):\n",
    "                    yield v\n",
    "        elif id(Type) in tv:\n",
    "            for v in tv[id(Type)]:\n",
    "                yield v\n",
    "        if hasattr(Type, 'enum'):\n",
    "            for v in Type.enum():\n",
    "                yield v\n",
    "\n",
    "    def __iter__(self):\n",
    "        for vs in self._typeid_to_values.values():\n",
    "            for v in vs:\n",
    "                yield v\n",
    "\n",
    "    def __init__(self, *values):\n",
    "        self._prev_cc = None\n",
    "        self._valueid_to_type = {}\n",
    "        self._typeid_to_values = {}\n",
    "        for v in values: self._add(v)\n",
    "\n",
    "    def __enter__(self):\n",
    "        assert self._prev_cc is None # We remember none\n",
    "        self._prev_cc, _current_context = _current_context, self\n",
    "\n",
    "    def __exit__(self,x,y,z):\n",
    "        assert _current_context is self\n",
    "        _current_context, self._prev_cc = self._prev_cc, None\n",
    "\n",
    "    __slots__ = '_typeid_to_values', '_valueid_to_type', '_prev_cc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I enjoy Python's context managers. Much prettier than init+`try`+`finally` everywhere.    \n",
    "I don't enjoy Python's string-based duck typing. The more precise approach is object-id-based definition, lacking all potential for name collision, but I'm not willing to add an extra line and an extra private method for each definition, and extra syntactic effort for access.    \n",
    "This night, I dreamt of being a pigeon.\n",
    "\n",
    "If nothing is done with knowledge, then it wasn't actually learned. Let's do some trivial testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ctx():\n",
    "    with Context(1,2,3):\n",
    "        ## `Context` is borderline useless without `compose`. Should have that.\n",
    "        print(Context.get(1))\n",
    "\n",
    "\n",
    "\n",
    "test_ctx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewriting sequel\n",
    "\n",
    "Our representation of computation looks good, so let's rewrite my incomplete rewriting.\n",
    "\n",
    "There are a few new features that we'd like to handle.    \n",
    "Namely, typed contexts and adjusting present in an `AutoFunc` (and the function `_merge_adjustments`).    \n",
    "But also, while we're at it, it would be nice to look both ways when crossing the graph street, and allow accumulating values on descent, not just ascent.    \n",
    "And, not rewrite the past of histories.\n",
    "\n",
    "But how can we do that?\n",
    "\n",
    "Let's begin from the end.\n",
    "\n",
    "Our `_postorder` already does not go into pasts, so re-using that seems useful.\n",
    "\n",
    "Our olden ascent is walking the post-order left-to-right.    \n",
    "The new descent is walking the post-order right-to-left.    \n",
    "Descent: `(graph_node, descent_estimate) -> (ascent_message, descent_estimate)`.    \n",
    "Ascent: `(graph_node, ascent_estimate, ascent_message) -> (node_becomes, ascent_estimate)`.    \n",
    "`descent_estimate`, `ascent_message`, `ascent_estimate` are variables that would need arrays in the state of rewriting.    \n",
    "All possible data flow dependencies now have adjustable communication channels; the full graph is handled, local neighborhood first.    \n",
    "An *everything* would be achievable in this component.\n",
    "\n",
    "We do need to merge `descent_estimate`s of parents and `ascent_estimate`s of children in an order-independent manner, with `_merge_adjustments`.\n",
    "\n",
    "Adjusting is execution backwards.    \n",
    "We'll need to return the final `ascent_estimate` from rewriting too if we hope to optimize it. It can represent how well the graph does on some measure, then optimization means computing the difference and passing it to `adjust`.    \n",
    "Firstly, adjust ascent right-to-left.    \n",
    "Then adjust descent left-to-right.\n",
    "\n",
    "But also.    \n",
    "A rewriting rule may well want to generate any expression that fits a type, for which we'd like to keep track of which expressions we've already visited for enumerating typed expressions. (In fact, this may well be among the only things our rewriting rules will do.)    \n",
    "(To be clear, a type is a pure transformation from an expression to a thing that should denote all its possible outputs. A typed context is a dict of either `'all'` or `id(type)` to a list of expressions.)\n",
    "\n",
    "*##[These typed contexts almost feel like a separate thing that we want to integrate. Develop+describe separately?]*\n",
    "\n",
    "*##[Uncertainty below.]*\n",
    "\n",
    "We haven't covered typed contexts before this.    \n",
    "A typed context's usage should be the `enum(ctx, type)` iterator (for use in `for struct in enum(ctx, t):`).    \n",
    "`ctx` is either a list of structures or a dictionary from `id(type)` to a list of structures.    \n",
    "*##[Two phases to typed context accumulation: descent comes first and gets the old, then ascent gets the new. Re-word all this in these terms.]*    \n",
    "If `type` has `.filter` or is a `Struct` with that, `enum(ctx, type)` enumerates all structures and filters out the unfitting ones. Else, it just selects structs whose types are `== type`.    \n",
    "With this…    \n",
    "An `AutoFunc` has a context of everything that every node in it can use when generating.    \n",
    "But we need to be able to refer to intermediate nodes too, without creating any cycles.    \n",
    "So, when we ascend, we need to build up a structure of what we have so far, getting every node's type with `_type_of` (which defers to `.type` if present). *##[…But isn't this just the first context-getting method in different words? Should we forget about the second one… But if we do, I don't think we'll be able to create cycles?]*    \n",
    "There are two ways to do it.    \n",
    "One is to look at the present we create: add each new node to the current context in the post-order. This is not *full* (there exist nodes to the right that would not create cycles), but randomizing the post-order could make it act as full over enough trials.    \n",
    "Two is to look at the past: take the context of all nodes in the previous `AutoFunc` and remove all the current parents.    \n",
    "*##[Also, mention something about re-computation of structs in child AutoFuncs and the need to preserve values. How would we do that?]*    \n",
    "To complicate things, this context can be passed into `AutoFunc`s by `ascend`, in which case the current context should not be modified in-place (but in other cases, it should be, for efficiency). The \"copy context if referenced elsewhere\" functionality can be done if `sys.getrefcount(ctx) > 2`. *##[Or maybe demanding that users g through copy_ctx(ctx) is better? And how would we update those contexts for existing AutoFuncs if the parent body changes?]*\n",
    "\n",
    "*##[This all sounds like trouble. Should just not bother, at least initially (but still discuss it, meaning, clean the above up).]*\n",
    "\n",
    "---\n",
    "\n",
    "I would like to take a moment to discuss virtual cycles in computation (\"edges\" that refer to a past/future value).    \n",
    "What we can do is mark a value with a \"can assign X to this\" or \"can adjust this into X\" type, both of which have `.outputs` that can then be passed into an `assign` or `adjust` function.    \n",
    "*##[…But if relying on the type, we need to create a struct before we can look at .outputs, meaning that cycles will be impossible to make. So… what other cyclicity channel can we have, adding something to the context before generating inputs?]*    \n",
    "We do need to always `enum_outputs` of the nodes returned from `ascend`, but then we'll be able to do everything we said in the **Composition** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum(ctx, Type):\n",
    "    \"\"\"Yields all structures in `ctx` that fit the `Type`.\"\"\"\n",
    "    ## if hasattr(Type, 'filter'):\n",
    "    ##   Go through every type+struct in ctx\n",
    "    ##     Yield all structs for which Type.filter(type) returns true\n",
    "    ## else:\n",
    "    ##   Yield all that are == to Type\n",
    "\n",
    "\n",
    "\n",
    "@attr(adjust = _rewrite_adjust)\n",
    "def rewrite(af, descend, ascend):\n",
    "    \"\"\"\n",
    "    Rewrites the body of an AutoFunc in-place. Returns the final ascent estimate.\n",
    "    \n",
    "    `descend` should be None or (graph_node, descent_estimate) -> (ascent_message, descent_estimate).\n",
    "    `ascend` should be (graph_node, ascent_estimate, ascent_message) -> (node_becomes, ascent_estimate).\n",
    "    `id(graph_node[0])` can be pattern-matched in these. `graph_node` will always be a `Struct`.\n",
    "    \n",
    "    Intended usage is to put neural networks as descent/ascent estimates/messages to predict the overall estimate,\n",
    "    and repeatedly rewrite nodes in any way while preserving their `history` (and going back at any time),\n",
    "    where each executable function should have several rewriting rules for it.\n",
    "    \"\"\"\n",
    "\n",
    "    base_ctx, po, ai = af._ctx, af._postorder, af._arg_indexes\n",
    "    descent_estimates, ascent_messages, ascent_estimates = [None]*len(po), [None]*len(po), [None]*len(po)\n",
    "    nodes_become = [None]*len(po)\n",
    "    ## Should also have `ctx`: a copy of `base_ctx`, and add a node to it on each iteration of descend then ascend.\n",
    "\n",
    "    with SetExecState(rewrite, (descent_estimates, ascent_messages, ascent_estimates, becomes_nodes)):\n",
    "        if descend is not None:\n",
    "            for i in reversed(range(len(po))):\n",
    "                # Descend:\n",
    "                ascent_messages[i], descent_estimate = descend(po[i], descent_estimates[i])\n",
    "                # Give descent estimate to children:\n",
    "                _give_to_children(po[i], ai[i], descent_estimates, descent_estimate)\n",
    "\n",
    "        for i in range(len(po)):\n",
    "            # Collect ascent estimate from children:\n",
    "            post, ae = _merge_from_children(po[i], ai[i], ascent_estimates, po, nodes_become)\n",
    "            # Ascend:\n",
    "            nodes_become[i], ascent_estimates[i] = ascend(post, ae, ascent_messages[i])\n",
    "\n",
    "        af._set_impl(nodes_become[-1])\n",
    "        return ascent_estimates[-1]\n",
    "\n",
    "\n",
    "\n",
    "def _merge_from_children(node, arg_indexes, estimates, old, new, create_post = True):\n",
    "    ae = None\n",
    "    post, changed = node, False\n",
    "    if _fallthrough(node) is node:\n",
    "        for j in range(1, len(node)):\n",
    "            ind = arg_indexes[j]\n",
    "            if ind is not None:\n",
    "                ae = _merge_adjustments(ae, estimates[ind])\n",
    "                if create_post and new[ind] is not old[ind]:\n",
    "                    if not changed: post = Struct(*node)\n",
    "                    post[j] = new[ind]\n",
    "                    changed = True\n",
    "    else:\n",
    "        ae = estimates[arg_indexes]\n",
    "    return post, ae\n",
    "\n",
    "def _give_to_children(n, arg_indexes, estimates, add):\n",
    "    if _fallthrough(n) is n:\n",
    "        for j in range(1, len(n)):\n",
    "            ind = arg_indexes[j]\n",
    "            if ind is not None:\n",
    "                estimates[ind] = _merge_adjustments(estimates[ind], add)\n",
    "    else:\n",
    "        estimates[arg_indexes] = _merge_adjustments(estimates[arg_indexes], add)\n",
    "\n",
    "\n",
    "\n",
    "def _rewrite_adjust(ins, out, dout):\n",
    "    po, ai = af._postorder, af._arg_indexes\n",
    "    with GetExecState(rewrite) as st:\n",
    "        descent_estimates, ascent_messages, ascent_estimates, becomes_nodes = st\n",
    "        ddescent_estimates, dascent_messages, dascent_estimates = [None]*len(po), [None]*len(po), [None]*len(po)\n",
    "\n",
    "        # Not sure why anyone would want to communicate to this all-or-nothing slot, but it's there just in case.\n",
    "        dnodes_become = [None]*len(po)\n",
    "\n",
    "        dnodes_become[-1], dascent_estimates[-1] = dout\n",
    "\n",
    "        for i in reversed(range(len(po))):\n",
    "            # Re-collect ascent estimate from children:\n",
    "            post, ae = _merge_from_children(po[i], ai[i], ascent_estimates, po, nodes_become)\n",
    "\n",
    "            # Adjust ascent and give estimate to children:\n",
    "            ins = post, ae, ascent_messages[i]\n",
    "            out = nodes_become[i], ascent_estimates[i]\n",
    "            dout = dnodes_become[i], dascent_estimates[i]\n",
    "\n",
    "            # Reverse (graph_node, ascent_estimate, ascent_message) -> (node_becomes, ascent_estimate).\n",
    "            dnb, dae, dam = adjust(ascend, ins, out, dout)\n",
    "\n",
    "            _give_to_children(po[i], ai[i], dnodes_become, dnb)\n",
    "            _give_to_children(po[i], ai[i], dascent_estimates, dae)\n",
    "            dascent_messages[i] = dam\n",
    "\n",
    "        if descend is not None:\n",
    "            for i in range(len(po)):\n",
    "                # Re-collect descent estimate & its change from children:\n",
    "                _, de = _merge_from_children(po[i], ai[i], descent_estimates, po, nodes_become, False)\n",
    "                _, dde = _merge_from_children(po[i], ai[i], ddescent_estimates, po, nodes_become, False)\n",
    "\n",
    "                ins = po[i], descent_estimates[i]\n",
    "                out = ascent_messages[i], de\n",
    "                dout = dascent_messages[i], dde\n",
    "\n",
    "                # Reverse (graph_node, descent_estimate) -> (ascent_message, descent_estimate).\n",
    "                _, ddescent_estimates[i] = adjust(descend, ins, out, dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "Let us pray to our God, the infinite nothing.    \n",
    "Let It deliver us from making any assumptions.    \n",
    "O fragile darkness, may our generators be complete.\n",
    "\n",
    "##[This is about NNs and types and ints and reals and bools and default ops that connect them, right?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Many:\n",
    "    \"\"\"Basically an array.\n",
    "    Multiple values at once, able to be decomposed into each with `access_many`.\n",
    "    When a value of a `many(…)` set is an input, becomes decomposed into each part.\n",
    "    When an output, generates each branch, then puts results into an array.\"\"\"\n",
    "    def __call__(self, *of):\n",
    "        return Struct(Many, *of)\n",
    "    def call(*of):\n",
    "        return list(of)\n",
    "    def outputs(self, struct, ctx): # Access each\n",
    "        return [Struct(access_many, struct, i-1) for i in range(1, len(self))]\n",
    "many = Many()\n",
    "\n",
    "# In general, the `index` structure can be computed,\n",
    "#   but if we only generate these calls with Many,\n",
    "#   the index can only be a number.\n",
    "@attr(type_of = lambda s: s[1][s[2]+1])\n",
    "def access_many(m, index):\n",
    "    return m[index]\n",
    "\n",
    "\n",
    "\n",
    "## All below must gain inputs/outputs info:\n",
    "class One:\n",
    "    \"\"\"Basically a choice.\n",
    "    Any value from ones listed, able to be recognized with `match`.\n",
    "    When a value of a `one(…)` set is an input, becomes pattern-matched.\n",
    "    When an output, returns a random item.\"\"\"\n",
    "    def __call__(self, *of):\n",
    "        return Struct(One, *of)\n",
    "    def call(*of):\n",
    "        return random.choice(of)\n",
    "    def outputs(self, struct, ctx):\n",
    "        b = { self[i]: AutoFunc(struct, self[i], ctx) for i in self[1:] }\n",
    "        return [Struct(match, struct, b)]\n",
    "one = One()\n",
    "\n",
    "\n",
    "\n",
    "class Match:\n",
    "    def __call__(self, value, branches):\n",
    "        if isinstance(branches, dict):\n",
    "            return branches[value](value)\n",
    "        return branches(value)\n",
    "match = Match()\n",
    "\n",
    "\n",
    "\n",
    "class Real:\n",
    "    \"\"\"Any scalar number from min to max.\"\"\"\n",
    "    def __call__(self, min, max):\n",
    "        return Struct(Real, min, max)\n",
    "    def call(min, max):\n",
    "        return random.uniform(min, max)\n",
    "    ## Defining filtering here would be nice.\n",
    "    ##   Maybe .inputs can do that by itself, actually, assuming that `ctx` is an array.\n",
    "real = Real()\n",
    "\n",
    "\n",
    "\n",
    "class Int:\n",
    "    \"\"\"Any integer from min to max.\"\"\"\n",
    "    def __call__(self, min, max):\n",
    "        return Struct(Int, min, max)\n",
    "    def call(min, max):\n",
    "        return random.randint(min, max)\n",
    "int = Int()\n",
    "\n",
    "\n",
    "\n",
    "class Bool:\n",
    "    \"\"\"Either False or True.\"\"\"\n",
    "    def __call__(self):\n",
    "        return Struct(Bool)\n",
    "    def call():\n",
    "        return random.randint(0,1) == 0\n",
    "bool = Bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting these to a Python-usable interface\n",
    "\n",
    "##[`@state(*ctx, *outputs)`, `@examples(*ex)`, function signatures.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
